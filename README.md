# RVC Voice Cloning System

A production-grade Retrieval-based Voice Conversion (RVC) system that works seamlessly on both local GPUs (via Gradio UI) and Google Colab (GPU-as-a-Service).

## ğŸ¯ Core Philosophy

**GitHub is the brain. Gradio is the face. Colab is just borrowed muscle.**

- Single source of truth: All logic lives in this repository
- Dual-mode execution: Local GPU or Colab GPU
- Identical results: Same code, same models, same outputs

## ğŸš€ Quick Start

### Mode A: Local GPU (Gradio UI)

```bash
# Install dependencies
pip install -r requirements.txt

# Download pretrained models (first time only)
python scripts/download_pretrained.py

# Launch Gradio UI
python app.py
```

### Mode B: Google Colab

1. Open `notebooks/rvc_colab.ipynb` in Google Colab
2. Run all cells
3. The notebook will clone this repo and set everything up automatically

## ğŸ“ Repository Structure

```
rvc-system/
â”œâ”€â”€ app.py                 # Gradio UI entry point
â”œâ”€â”€ core/                  # Core ML logic (no UI dependencies)
â”‚   â”œâ”€â”€ audio/            # Audio preprocessing
â”‚   â”œâ”€â”€ features/         # Feature extraction (HuBERT, F0, RMVPE)
â”‚   â”œâ”€â”€ model/            # RVC model definition
â”‚   â”œâ”€â”€ training/         # Training pipeline
â”‚   â””â”€â”€ inference/        # Voice conversion pipeline
â”œâ”€â”€ utils/                # Utilities (device detection, registry)
â”œâ”€â”€ models/               # Trained voice models (auto-discovered)
â”œâ”€â”€ notebooks/            # Colab notebook
â””â”€â”€ pretrained/           # Pretrained models (HuBERT, etc.)
```

## ğŸ¨ Features

- **Training UI**: Upload audio, train custom voices
- **Inference UI**: Convert audio to any trained voice
- **Dynamic Voice Registry**: Auto-discovers trained models
- **GPU-Agnostic**: Auto-detects CUDA/MPS/CPU
- **Production-Ready**: Clean, modular, maintainable code

## ğŸ“ Usage

### Training a New Voice

1. Open Gradio UI (local) or Colab notebook
2. Go to "Training" tab
3. Upload audio files (WAV format recommended)
4. Enter a unique person/speaker name
5. Click "Train Model"
6. Wait for training to complete

Trained models are saved to `models/<person_name>/` and automatically appear in the inference dropdown.

### Voice Conversion

1. Go to "Inference" tab
2. Upload source audio
3. Select target voice from dropdown
4. Click "Convert Voice"
5. Download or play the result

## ğŸ”§ Requirements

- Python 3.8+
- CUDA-capable GPU (recommended) or Apple Silicon (MPS) or CPU fallback
- See `requirements.txt` for full dependencies

## ğŸ“š Architecture

The system is designed with clear separation of concerns:

- **Core Logic**: Pure Python, no UI dependencies
- **UI Layer**: Thin Gradio wrapper over core functions
- **Colab Integration**: Minimal orchestration, calls core modules

This ensures:
- Same code runs in both modes
- Easy to test and maintain
- Simple to extend (new models, real-time inference, etc.)

## ğŸ¤ Contributing

This is a production system designed for long-term maintenance. Code quality, modularity, and documentation are priorities.

## ğŸ“„ License

[Add your license here]
