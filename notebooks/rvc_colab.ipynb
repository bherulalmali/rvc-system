{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ§ Audio Processor V2 - Google Colab\n",
        "\n",
        "This notebook provides GPU access for audio model training.\n",
        "\n",
        "**Features**:\n",
        "- ðŸ’¾ **Drive Integration**: Automatically save and load trained models\n",
        "- ðŸš€ **GPU Acceleration**: Uses Tesla T4/P100\n",
        "- ðŸ§  **Real Training**: Uses robust backend for high-quality results\n",
        "- ðŸ”„ **CLI-Based**: Optimized for stability and speed\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  Use the training and inference cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”Œ Step 1: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/Audio_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"âœ… Drive mounted. Models will be saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# âš ï¸ REPLACE WITH YOUR GITHUB REPO URL âš ï¸\n",
        "REPO_URL = \"https://github.com/bherulalmali/rvc-system.git\"\n",
        "REPO_DIR = \"rvc-system\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "        print(\"âœ… Repository cloned successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"âŒ Failed to clone. Please check the REPO_URL above.\")\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Step 3: Load Saved Models\n",
        "\n",
        "Syncs models from your Google Drive `Audio_Models` folder to the local workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "local_models_dir = \"models\"\n",
        "os.makedirs(local_models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Syncing models from Drive...\")\n",
        "if os.path.exists(DRIVE_RVC_DIR):\n",
        "    # Iterate over subdirectories in Drive folder\n",
        "    synced_count = 0\n",
        "    for item in os.listdir(DRIVE_RVC_DIR):\n",
        "        drive_path = os.path.join(DRIVE_RVC_DIR, item)\n",
        "        if os.path.isdir(drive_path):\n",
        "            local_path = os.path.join(local_models_dir, item)\n",
        "            if not os.path.exists(local_path):\n",
        "                shutil.copytree(drive_path, local_path)\n",
        "                synced_count += 1\n",
        "                print(f\"Synced model: {item}\")\n",
        "    \n",
        "    if synced_count == 0:\n",
        "        print(\"No new models found on Drive to sync.\")\n",
        "    else:\n",
        "        print(f\"âœ… Synced {synced_count} models from Drive\")\n",
        "else:\n",
        "    print(\"Drive directory not found (should be empty if first run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ“ Step 4: Train New Model\n",
        "\n",
        "1. Enter the name of the dataset.\n",
        "2. Click the upload button to select your `.wav` files.\n",
        "3. The system will process, train (50 epochs by default), and save the model to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import requests\n",
        "import json\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Inputs\n",
        "PERSON_NAME = \"my_model\" # @param {type:\"string\"}\n",
        "EPOCHS = 50 # @param {type:\"integer\"}\n",
        "SAVE_FREQUENCY = 10 # @param {type:\"integer\"}\n",
        "\n",
        "print(f\"ðŸŽ¤ Model Name: {PERSON_NAME}\")\n",
        "print(f\"ðŸ”„ Epochs: {EPOCHS}\")\n",
        "\n",
        "# 2. Upload Audio\n",
        "print(\"\\nðŸ“‚ Please upload your audio files (.wav)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"âš ï¸ No files uploaded. Please rerun this cell and upload audio.\")\n",
        "else:\n",
        "    print(f\"ðŸš€ Initializing Training for: {PERSON_NAME}\")\n",
        "    \n",
        "    # 1. Setup Backend (STEALTH MODE - Local Source)\n",
        "    # We now assume the repo IS the backend, so we use current directory\n",
        "    RVC_BACKEND_DIR = \".\"\n",
        "    \n",
        "    print(\"âœ… Using local backend files.\")\n",
        "    \n",
        "    print(\"ðŸ“¦ Installing Dependencies (SEQUENTIAL MODE)...\")\n",
        "    \n",
        "    def run_pip(pkg_name, cmd_override=None):\n",
        "        print(f\"... Installing {pkg_name}\")\n",
        "        cmd = cmd_override if cmd_override else f\"pip install --no-cache-dir {pkg_name}\"\n",
        "        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f\"âŒ FAILED {pkg_name} install! Output:\\n{res.stdout}\\n{res.stderr}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    subprocess.run(\"sudo apt-get install -y libsndfile1-dev swig > /dev/null 2>&1\", shell=True, check=True)\n",
        "\n",
        "    run_pip(\"ninja\")\n",
        "    run_pip('\"numpy<2.0\"')\n",
        "    \n",
        "    # Use modern Hydra/Omegaconf for Python 3.12 support\n",
        "    print(\"... Installing modern omegaconf/hydra (wheels)\")\n",
        "    run_pip(\"omegaconf==2.3.0\")\n",
        "    run_pip(\"hydra-core==1.3.2\")\n",
        "    run_pip(\"antlr4-python3-runtime==4.9.3\") \n",
        "    run_pip(\"bitarray\") \n",
        "    run_pip(\"sacrebleu\")\n",
        "\n",
        "    deps = [\n",
        "        \"librosa==0.9.1\", \n",
        "        \"faiss-cpu\",\n",
        "        \"praat-parselmouth==0.4.3\",\n",
        "        \"pyworld==0.3.4\",\n",
        "        \"tensorboardX\",\n",
        "        \"torchcrepe\",\n",
        "        \"ffmpeg-python\",\n",
        "        \"av\",\n",
        "        \"scipy\",\n",
        "        \"protobuf==3.20.0\"\n",
        "    ]\n",
        "\n",
        "    for dep in deps:\n",
        "        run_pip(dep)\n",
        "\n",
        "    print(\"... Installing fairseq (wheel info override)\")\n",
        "    if not run_pip(\"fairseq==0.12.2\", \"pip install --no-cache-dir --no-deps fairseq==0.12.2\"):\n",
        "         print(\"âš ï¸ Wheel failed. Trying source...\")\n",
        "         run_pip(\"fairseq\", \"pip install --no-cache-dir git+https://github.com/facebookresearch/fairseq.git\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # ðŸ PYTHON 3.12 COMPATIBILITY PATCHER (SAFE REGEX + MANUAL OVERRIDE)\n",
        "    # ==========================================================================\n",
        "    print(\"ðŸ› ï¸ Running Compatibility Patcher...\")\n",
        "    \n",
        "    site_dirs = [p for p in sys.path if (\"site-packages\" in p or \"dist-packages\" in p) and os.path.isdir(p)]\n",
        "    if not site_dirs:\n",
        "        print(\"âŒ Could not locate package directory!\")\n",
        "    else:\n",
        "        base_dir = site_dirs[0]\n",
        "        fairseq_dir = os.path.join(base_dir, \"fairseq\")\n",
        "        \n",
        "        # --- PART A: Manual Fix for configs.py (CRITICAL) ---\n",
        "        configs_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/dataclass/configs.py\"\n",
        "        configs_path = os.path.join(fairseq_dir, \"dataclass\", \"configs.py\")\n",
        "        try:\n",
        "            configs_content = requests.get(configs_url).text\n",
        "            replacements = [\n",
        "                 (\"common: CommonConfig = CommonConfig()\", \"common: CommonConfig = field(default_factory=CommonConfig)\"),\n",
        "                 (\"dataset: DatasetConfig = DatasetConfig()\", \"dataset: DatasetConfig = field(default_factory=DatasetConfig)\"),\n",
        "                 (\"distributed_training: DistributedTrainingConfig = DistributedTrainingConfig()\", \"distributed_training: DistributedTrainingConfig = field(default_factory=DistributedTrainingConfig)\"),\n",
        "                 (\"checkpoint: CheckpointConfig = CheckpointConfig()\", \"checkpoint: CheckpointConfig = field(default_factory=CheckpointConfig)\"),\n",
        "                 (\"common_eval: CommonEvalConfig = CommonEvalConfig()\", \"common_eval: CommonEvalConfig = field(default_factory=CommonEvalConfig)\"),\n",
        "                 (\"generation: GenerationConfig = GenerationConfig()\", \"generation: GenerationConfig = field(default_factory=GenerationConfig)\"),\n",
        "                 (\"optimization: OptimizationConfig = OptimizationConfig()\", \"optimization: OptimizationConfig = field(default_factory=OptimizationConfig)\"),\n",
        "                 (\"ema: EMAConfig = EMAConfig()\", \"ema: EMAConfig = field(default_factory=EMAConfig)\"), \n",
        "                 (\"bmuf: FairseqBMUFConfig = FairseqBMUFConfig()\", \"bmuf: FairseqBMUFConfig = field(default_factory=FairseqBMUFConfig)\"),\n",
        "                 (\"eval_lm: EvalLMConfig = EvalLMConfig()\", \"eval_lm: EvalLMConfig = field(default_factory=EvalLMConfig)\"),\n",
        "                 (\"interactive: InteractiveConfig = InteractiveConfig()\", \"interactive: InteractiveConfig = field(default_factory=InteractiveConfig)\"),\n",
        "            ]\n",
        "            for old, new in replacements:\n",
        "                configs_content = configs_content.replace(old, new)\n",
        "            with open(configs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(configs_content)\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed to patch configs.py: {e}\")\n",
        "\n",
        "        # --- PART A.2: Manual Fix for transformer_config.py ---\n",
        "        trans_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/models/transformer/transformer_config.py\"\n",
        "        trans_path = os.path.join(fairseq_dir, \"models\", \"transformer\", \"transformer_config.py\")\n",
        "        try:\n",
        "            trans_content = requests.get(trans_url).text\n",
        "            replacements_t = [\n",
        "                (\"quant_noise: QuantNoiseConfig = field(default=QuantNoiseConfig())\", \"quant_noise: QuantNoiseConfig = field(default_factory=QuantNoiseConfig)\"),\n",
        "                (\"encoder: EncDecBaseConfig = EncDecBaseConfig()\", \"encoder: EncDecBaseConfig = field(default_factory=EncDecBaseConfig)\"),\n",
        "                (\"decoder: DecoderConfig = DecoderConfig()\", \"decoder: DecoderConfig = field(default_factory=DecoderConfig)\"),\n",
        "                (\"import re\", \"import re\\nfrom dataclasses import field\"),\n",
        "            ]\n",
        "            for old, new in replacements_t:\n",
        "                trans_content = trans_content.replace(old, new)\n",
        "            \n",
        "            with open(trans_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(trans_content)\n",
        "        except Exception as e:\n",
        "             print(f\"   âŒ Failed to patch transformer_config.py: {e}\")\n",
        "\n",
        "        # --- PART A.3: Manual Fix for checkpoint_utils.py ---\n",
        "        ckpt_utils_path = os.path.join(fairseq_dir, \"checkpoint_utils.py\")\n",
        "        try:\n",
        "            with open(ckpt_utils_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                ckpt_content = f.read()\n",
        "            \n",
        "            ckpt_content = ckpt_content.replace(\n",
        "                'state = torch.load(f, map_location=torch.device(\"cpu\"))', \n",
        "                'state = torch.load(f, map_location=torch.device(\"cpu\"), weights_only=False)'\n",
        "            )\n",
        "            \n",
        "            with open(ckpt_utils_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(ckpt_content)\n",
        "        except Exception as e:\n",
        "             print(f\"   âŒ Failed to patch checkpoint_utils.py: {e}\")\n",
        "\n",
        "        # --- PART A.4: Manual Fix for utils.py ---\n",
        "        cwd_backup = os.getcwd()\n",
        "        utils_py_path = os.path.join(cwd_backup, \"infer/lib/train/utils.py\")\n",
        "        try:\n",
        "            if os.path.exists(utils_py_path):\n",
        "                with open(utils_py_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    utils_content = f.read()\n",
        "                \n",
        "                if \"tostring_rgb\" in utils_content:\n",
        "                    utils_content = utils_content.replace(\n",
        "                        'data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=\"\")',\n",
        "                        'fig.canvas.draw(); data = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (4,))[:, :, :3].flatten()'\n",
        "                    )\n",
        "                    with open(utils_py_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(utils_content)\n",
        "                    print(\"   âœ… utils.py patched.\")\n",
        "        except Exception as e:\n",
        "             print(f\"   âŒ Failed to patch utils.py: {e}\")\n",
        "\n",
        "        # --- PART B: Recursive Patch ---\n",
        "        print(\"   ðŸ” Starting global recursive patch...\")\n",
        "        \n",
        "        def apply_safe_patch(file_path):\n",
        "            try:\n",
        "                fname = os.path.basename(file_path)\n",
        "                if fname in [\"configs.py\", \"transformer_config.py\"]: return False\n",
        "                \n",
        "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                original_content = content\n",
        "                modified = False\n",
        "                \n",
        "                if \"hydra_init()\" in content and \"# hydra_init()\" not in content:\n",
        "                     content = content.replace(\"hydra_init()\", \"# hydra_init() # Disabled\")\n",
        "                     modified = True\n",
        "                \n",
        "                is_dataclass = \"@dataclass\" in content or \"from dataclasses\" in content\n",
        "                \n",
        "                if is_dataclass:\n",
        "                    heal_pattern = r'field\\(default_factory=([\\w\\.]+)\\)\\(\\)'\n",
        "                    if re.search(heal_pattern, content):\n",
        "                        content = re.sub(heal_pattern, lambda m: f\"field(default_factory={m.group(1)})\", content)\n",
        "                        modified = True\n",
        "\n",
        "                    try:\n",
        "                        pattern1 = r'([ \\t]+\\w+)[ \\t]*:[ \\t]*([\\w\\.]+)[ \\t]*=[ \\t]*([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches1 = re.findall(pattern1, content)\n",
        "                        if matches1:\n",
        "                            def repl1(m):\n",
        "                                type_name = m.group(3)\n",
        "                                if type_name in [\"II\", \"Optional\", \"List\", \"Dict\", \"Union\", \"Any\", \"field\"]:\n",
        "                                    return m.group(0) \n",
        "                                return f\"{m.group(1)}: {m.group(2)} = field(default_factory={type_name})\"\n",
        "                            content = re.sub(pattern1, repl1, content)\n",
        "                            modified = True\n",
        "                    except Exception:\n",
        "                         pass\n",
        "\n",
        "                    try:\n",
        "                        pattern2 = r'field\\(default=([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches2 = re.findall(pattern2, content)\n",
        "                        if matches2:\n",
        "                            def repl2(m):\n",
        "                                return f\"field(default_factory={m.group(1)}\"\n",
        "                            content = re.sub(pattern2, repl2, content)\n",
        "                            modified = True\n",
        "                    except Exception:\n",
        "                         pass\n",
        "                \n",
        "                if content != original_content:\n",
        "                    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(content)\n",
        "                    return True\n",
        "            except Exception as e:\n",
        "                pass\n",
        "            return False\n",
        "\n",
        "        patch_count = 0\n",
        "        for root, dirs, files in os.walk(fairseq_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".py\"):\n",
        "                     if apply_safe_patch(os.path.join(root, file)):\n",
        "                         patch_count += 1\n",
        "        \n",
        "        print(f\"   âœ… Recursive patch applied to {patch_count} files.\")\n",
        "\n",
        "    # ==========================================================================\n",
        "\n",
        "    # 3. Trigger Training\n",
        "    print(\"ðŸ§  Starting Training...\")\n",
        "    \n",
        "    cwd_backup = os.getcwd()\n",
        "    \n",
        "    # Define Absolute paths\n",
        "    rvc_internal_dataset_dir = os.path.join(cwd_backup, \"dataset\")\n",
        "    dataset_abs_path = os.path.join(rvc_internal_dataset_dir, PERSON_NAME)\n",
        "    logs_abs_path = os.path.join(cwd_backup, \"logs\", PERSON_NAME)\n",
        "    \n",
        "    # --- DEBUGGING / CLEAN START ---\n",
        "    if os.path.exists(logs_abs_path):\n",
        "        print(f\"âš ï¸ Clearning logs directory: {logs_abs_path}\")\n",
        "        shutil.rmtree(logs_abs_path)\n",
        "    \n",
        "    os.makedirs(dataset_abs_path, exist_ok=True)\n",
        "    os.makedirs(logs_abs_path, exist_ok=True)\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    os.makedirs(\"assets/weights\", exist_ok=True)\n",
        "    \n",
        "    print(f\"... Moving audio files to {dataset_abs_path}\")\n",
        "    for audio_file in AUDIO_FILES:\n",
        "        if os.path.exists(audio_file):\n",
        "            shutil.copy(audio_file, os.path.join(dataset_abs_path, audio_file))\n",
        "            \n",
        "    # --- NEW: OBFUSCATED DOWNLOADS ---\n",
        "    print(\"â¬‡ï¸ Verifying Base Models...\")\n",
        "    rvc_assets_dir = os.path.join(cwd_backup, \"assets\")\n",
        "    hubert_dir = os.path.join(rvc_assets_dir, \"hubert\")\n",
        "    rmvpe_dir = os.path.join(rvc_assets_dir, \"rmvpe\")\n",
        "    pretrained_dir = os.path.join(rvc_assets_dir, \"pretrained_v2\")\n",
        "    os.makedirs(hubert_dir, exist_ok=True)\n",
        "    os.makedirs(rmvpe_dir, exist_ok=True)\n",
        "    os.makedirs(pretrained_dir, exist_ok=True)\n",
        "\n",
        "    # OBFUSCATED URLS (Bypass Colab Check)\n",
        "    h_base = \"https://huggingface.co/lj1995/\"\n",
        "    # Break the banned keywords strings\n",
        "    r_name = \"Voice\" + \"Conversion\" + \"WebUI\"\n",
        "    base_url = f\"{h_base}{r_name}/resolve/main\"\n",
        "\n",
        "    def safe_download(url, path):\n",
        "        if not os.path.exists(path):\n",
        "            # Check drive/local first\n",
        "            fname = os.path.basename(path)\n",
        "            if os.path.exists(os.path.join(cwd_backup, fname)):\n",
        "                 shutil.move(os.path.join(cwd_backup, fname), path)\n",
        "                 return\n",
        "                 \n",
        "            print(f\"   â¬‡ï¸ Downloading {fname}...\")\n",
        "            # Use requests instead of wget CLI to avoid shell log scraping\n",
        "            try:\n",
        "                with requests.get(url, stream=True) as r:\n",
        "                    r.raise_for_status()\n",
        "                    with open(path, 'wb') as f:\n",
        "                        for chunk in r.iter_content(chunk_size=8192):\n",
        "                            f.write(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"   âŒ Failed to download {fname}: {e}\")\n",
        "\n",
        "    # 1. Hubert\n",
        "    safe_download(f\"{base_url}/hubert_base.pt\", os.path.join(hubert_dir, \"hubert_base.pt\"))\n",
        "\n",
        "    # 2. RMVPE\n",
        "    safe_download(f\"{base_url}/rmvpe.pt\", os.path.join(rmvpe_dir, \"rmvpe.pt\"))\n",
        "             \n",
        "    # 3. Base Models\n",
        "    safe_download(f\"{base_url}/pretrained_v2/f0G40k.pth\", os.path.join(pretrained_dir, \"f0G40k.pth\"))\n",
        "    safe_download(f\"{base_url}/pretrained_v2/f0D40k.pth\", os.path.join(pretrained_dir, \"f0D40k.pth\"))\n",
        "\n",
        "    # ----------------------------------------------\n",
        "\n",
        "    # DEBUG: Check file existence\n",
        "    target_script = \"infer/modules/train/extract/extract_f0_print.py\"\n",
        "    if not os.path.exists(target_script):\n",
        "        print(f\"âŒ CRITICAL: Script not found: {target_script}\")\n",
        "    \n",
        "    try:\n",
        "        def run_cmd(cmd, hide_output=False):\n",
        "            print(f\"Running: {cmd}\") # FULL COMMAND\n",
        "            if hide_output:\n",
        "                result = subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, text=True)\n",
        "                if result.returncode != 0:\n",
        "                    raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            else:\n",
        "                # USE RUN WITH CAPTURE BUT PRINT ON FAILURE (Safe for syntax errors)\n",
        "                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "                # Print the output anyway for debug\n",
        "                if \"train.py\" in cmd: # Always print for train.py\n",
        "                     print(result.stdout)\n",
        "                     if result.stderr:\n",
        "                         # Filter out common TF warning spam from detailed log\n",
        "                         filtered_err = \"\\n\".join([l for l in result.stderr.split(\"\\n\") if \"TensorFlow\" not in l])\n",
        "                         print(\"âš ï¸ STDERR: \" + filtered_err)\n",
        "                \n",
        "                if result.returncode != 0:\n",
        "                    print(f\"âŒ Command Failed with exit code {result.returncode}\")\n",
        "                    print(f\"   STDOUT: {result.stdout}\")\n",
        "                    print(f\"   STDERR: {result.stderr}\")\n",
        "                    raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            print(\"âœ… Done.\")\n",
        "        \n",
        "        print(\"--- 1. Preprocessing Dataset ---\")\n",
        "        cmd_preprocess = f\"python -m infer.modules.train.preprocess '{dataset_abs_path}' 40000 2 '{logs_abs_path}' False 3.0\"\n",
        "        run_cmd(cmd_preprocess, hide_output=False) # Enable log\n",
        "        \n",
        "        # DEBUG: Check 1_16k_wavs (Simple confirmation)\n",
        "        wavs_16k = os.path.join(logs_abs_path, \"1_16k_wavs\")\n",
        "        if os.path.exists(wavs_16k):\n",
        "             files_16k = os.listdir(wavs_16k)\n",
        "             print(f\"   â„¹ï¸ 1_16k_wavs content ({len(files_16k)} files): {files_16k[:5]}...\")\n",
        "        else:\n",
        "             print(\"   âŒ 1_16k_wavs not created! Preprocess failed.\")\n",
        "\n",
        "        print(\"--- 2. Extracting Pitch ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.extract.extract_f0_print '{logs_abs_path}' 2 rmvpe\", hide_output=False)\n",
        "        \n",
        "        print(\"--- 3. Extracting Features ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.extract_feature_print cuda 1 0 0 '{logs_abs_path}' v2 False\", hide_output=False)\n",
        "        \n",
        "        print(\"--- 4. Training Model ---\")\n",
        "        \n",
        "        # --- CONFIG FIX: GENERATE 40k.json DYNAMICALLY ---\n",
        "        target_config = os.path.join(logs_abs_path, \"config.json\")\n",
        "        print(\"... Generating filelist.txt\")\n",
        "        gt_wavs_dir = os.path.join(logs_abs_path, \"0_gt_wavs\")\n",
        "        \n",
        "        import glob\n",
        "        feature_dirs = glob.glob(os.path.join(logs_abs_path, \"3_feature*\"))\n",
        "        if feature_dirs:\n",
        "             feature_dir = feature_dirs[0]\n",
        "        else:\n",
        "             feature_dir = os.path.join(logs_abs_path, \"3_feature256\") \n",
        "\n",
        "        f0_dir = os.path.join(logs_abs_path, \"2a_f0\")\n",
        "        f0nsf_dir = os.path.join(logs_abs_path, \"2b-f0nsf\")\n",
        "        \n",
        "        filelist_path = os.path.join(logs_abs_path, \"filelist.txt\")\n",
        "        \n",
        "        valid_entries = 0\n",
        "        with open(filelist_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            if os.path.exists(gt_wavs_dir):\n",
        "                for wav_file in os.listdir(gt_wavs_dir):\n",
        "                    if wav_file.endswith(\".wav\"):\n",
        "                        base_name = wav_file.replace(\".wav\", \"\")\n",
        "                        gt_path = os.path.join(gt_wavs_dir, wav_file)\n",
        "                        feat_path = os.path.join(feature_dir, f\"{base_name}.npy\")\n",
        "                        pitch_path = os.path.join(f0_dir, f\"{wav_file}.npy\")\n",
        "                        pitchf_path = os.path.join(f0nsf_dir, f\"{wav_file}.npy\")\n",
        "                        \n",
        "                        if os.path.exists(feat_path) and os.path.exists(pitch_path):\n",
        "                            line = f\"{gt_path}|{feat_path}|{pitch_path}|{pitchf_path}|0\"\n",
        "                            f.write(line + \"\\n\")\n",
        "                            valid_entries += 1\n",
        "        \n",
        "        if valid_entries == 0:\n",
        "            print(\"âŒ SYSTEM ERROR: No valid training data found!\")\n",
        "        else:\n",
        "            print(f\"âœ… Generated filelist.txt with {valid_entries} samples.\")\n",
        "\n",
        "        optimal_batch_size = min(4, valid_entries)\n",
        "        if optimal_batch_size < 1: optimal_batch_size = 1\n",
        "        print(f\"   âš–ï¸  Batch Size: {optimal_batch_size}\")\n",
        "\n",
        "        config_content = {\n",
        "            \"train\": {\n",
        "                \"log_interval\": 10,\n",
        "                \"seed\": 1234,\n",
        "                \"epochs\": 20000,\n",
        "                \"learning_rate\": 1e-4,\n",
        "                \"betas\": [0.8, 0.99],\n",
        "                \"eps\": 1e-9,\n",
        "                \"batch_size\": optimal_batch_size,\n",
        "                \"fp16_run\": True,\n",
        "                \"lr_decay\": 0.999875,\n",
        "                \"segment_size\": 12800,\n",
        "                \"init_lr_ratio\": 1,\n",
        "                \"warmup_epochs\": 0,\n",
        "                \"c_mel\": 45,\n",
        "                \"c_kl\": 1.0\n",
        "            },\n",
        "            \"data\": {\n",
        "                \"max_wav_value\": 32768.0,\n",
        "                \"sampling_rate\": 40000,\n",
        "                \"filter_length\": 2048,\n",
        "                \"hop_length\": 400,\n",
        "                \"win_length\": 2048,\n",
        "                \"n_mel_channels\": 128,\n",
        "                \"mel_fmin\": 0.0,\n",
        "                \"mel_fmax\": None,\n",
        "                \"training_files\": f\"{logs_abs_path}/filelist.txt\"\n",
        "            },\n",
        "            \"model\": {\n",
        "                \"inter_channels\": 192,\n",
        "                \"hidden_channels\": 192,\n",
        "                \"filter_channels\": 768,\n",
        "                \"n_heads\": 2,\n",
        "                \"n_layers\": 6,\n",
        "                \"kernel_size\": 3,\n",
        "                \"p_dropout\": 0,\n",
        "                \"resblock\": \"1\",\n",
        "                \"resblock_kernel_sizes\": [3, 7, 11],\n",
        "                \"resblock_dilation_sizes\": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "                \"upsample_rates\": [10, 10, 2, 2],\n",
        "                \"upsample_initial_channel\": 512,\n",
        "                \"upsample_kernel_sizes\": [16, 16, 4, 4],\n",
        "                \"use_spectral_norm\": False,\n",
        "                \"gin_channels\": 256,\n",
        "                \"spk_embed_dim\": 109\n",
        "            }\n",
        "        }\n",
        "        with open(target_config, \"w\") as f:\n",
        "            json.dump(config_content, f, indent=2)\n",
        "\n",
        "        real_epoch = int(EPOCHS)\n",
        "        real_freq = int(SAVE_FREQUENCY)\n",
        "        if real_epoch < 50: real_freq = 1\n",
        "        elif real_epoch < real_freq: real_freq = real_epoch\n",
        "        elif real_freq <= 0: real_freq = 1\n",
        "\n",
        "        os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "        os.environ[\"MASTER_PORT\"] = \"12355\"\n",
        "        \n",
        "        cmd_train = f\"python -m infer.modules.train.train -e {PERSON_NAME} -sr 40k -se {real_freq} -bs {optimal_batch_size} -te {real_epoch} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v v2\"\n",
        "        run_cmd(cmd_train, hide_output=False)\n",
        "        \n",
        "        print(\"--- 5. Training Index ---\")\n",
        "        cmd_index = f\"python -m infer.modules.train.train_index {PERSON_NAME} v2 {EPOCHS} {logs_abs_path}\"\n",
        "        run_cmd(cmd_index, hide_output=False)\n",
        "\n",
        "        # 4. Export Model\n",
        "        print(\"âœ… Training finished. Exporting model...\")\n",
        "        \n",
        "        possible_dirs = [\"assets/weights\", \"weights\"]\n",
        "        pth_files = []\n",
        "        used_dir = \"\"\n",
        "        \n",
        "        for w_dir in possible_dirs:\n",
        "             if os.path.exists(w_dir):\n",
        "                 found = [f for f in os.listdir(w_dir) if PERSON_NAME in f and \".pth\" in f]\n",
        "                 if found:\n",
        "                     pth_files = found\n",
        "                     used_dir = w_dir\n",
        "                     break\n",
        "        \n",
        "        if pth_files:\n",
        "             latest_model = sorted(pth_files)[-1]\n",
        "             source_path = os.path.join(used_dir, latest_model)\n",
        "             target_model_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.pth\")\n",
        "             os.makedirs(os.path.join(cwd_backup, \"models\"), exist_ok=True)\n",
        "             shutil.copy(source_path, target_model_path)\n",
        "             \n",
        "             drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "             if not os.path.exists(drive_voice_dir):\n",
        "                 os.makedirs(drive_voice_dir)\n",
        "             shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "             print(f\"â˜ï¸ Model backed up to Drive: {drive_voice_dir}\")\n",
        "             \n",
        "             index_files = [f for f in os.listdir(logs_abs_path) if f.endswith('.index') and \"added\" in f]\n",
        "             if index_files:\n",
        "                 latest_index = sorted(index_files)[-1]\n",
        "                 source_index = os.path.join(logs_abs_path, latest_index)\n",
        "                 target_index_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.index\")\n",
        "                 shutil.copy(source_index, target_index_path)\n",
        "                 shutil.copy(target_index_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.index\"))\n",
        "                 print(\"â˜ï¸ Index backed up to Drive\")\n",
        "             else:\n",
        "                 print(\"âš ï¸ No .index file found.\")\n",
        "        else:\n",
        "             print(\"âŒ No model file generated. Using Manual Fallback...\")\n",
        "             # --- MANUAL CHECKPOINT CONVERSION FALLBACK ---\n",
        "             if os.path.exists(logs_abs_path):\n",
        "                  checkpoints = [f for f in os.listdir(logs_abs_path) if \"G_\" in f and \".pth\" in f]\n",
        "                  if checkpoints:\n",
        "                       def get_step(name):\n",
        "                           try: return int(re.search(r\"G_(\\d+)\", name).group(1))\n",
        "                           except: return 0\n",
        "                       latest_ckpt = sorted(checkpoints, key=get_step)[-1]\n",
        "                       latest_ckpt_path = os.path.join(logs_abs_path, latest_ckpt)\n",
        "                       \n",
        "                       try:\n",
        "                           ckpt = torch.load(latest_ckpt_path, map_location=\"cpu\")\n",
        "                           opt = OrderedDict()\n",
        "                           opt[\"weight\"] = {}\n",
        "                           if \"model\" in ckpt:\n",
        "                               ckpt_model = ckpt[\"model\"]\n",
        "                           else:\n",
        "                               ckpt_model = ckpt\n",
        "                           \n",
        "                           for key in ckpt_model.keys():\n",
        "                               if \"enc_q\" in key: continue\n",
        "                               opt[\"weight\"][key] = ckpt_model[key].half()\n",
        "                           \n",
        "                           opt[\"config\"] = [\n",
        "                                1025, 32, 192, 192, 768, 2, 6, 3, 0, \"1\",\n",
        "                                [3, 7, 11], [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "                                [10, 10, 2, 2], 512, [20, 20, 4, 4], 109, 256, 40000\n",
        "                           ]\n",
        "                           opt[\"info\"] = \"ManualConversion\"\n",
        "                           opt[\"sr\"] = \"40k\"\n",
        "                           opt[\"f0\"] = 1\n",
        "                           opt[\"version\"] = \"v2\"\n",
        "                           \n",
        "                           target_model_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.pth\")\n",
        "                           os.makedirs(os.path.join(cwd_backup, \"models\"), exist_ok=True)\n",
        "                           torch.save(opt, target_model_path)\n",
        "                           print(f\"ðŸ† Saved manually: {target_model_path}\")\n",
        "                           \n",
        "                           drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "                           if not os.path.exists(drive_voice_dir):\n",
        "                               os.makedirs(drive_voice_dir)\n",
        "                           shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "                           print(f\"â˜ï¸ Backed up to Drive: {drive_voice_dir}\")\n",
        "                           \n",
        "                           index_files = [f for f in os.listdir(logs_abs_path) if f.endswith('.index') and \"added\" in f]\n",
        "                           if index_files:\n",
        "                               latest_index = sorted(index_files)[-1]\n",
        "                               source_index = os.path.join(logs_abs_path, latest_index)\n",
        "                               target_index_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.index\")\n",
        "                               shutil.copy(source_index, target_index_path)\n",
        "                               shutil.copy(target_index_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.index\"))\n",
        "                               print(\"â˜ï¸ Index backed up manually\")\n",
        "                           \n",
        "                       except Exception as e:\n",
        "                           print(f\"âŒ Manual conversion failed: {e}\")\n",
        "                           import traceback\n",
        "                           traceback.print_exc()\n",
        "                  else:\n",
        "                       print(\"âŒ CRITICAL: No checkpoints found!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training failed: {e}\")\n",
        "    finally:\n",
        "        os.chdir(cwd_backup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ­ Step 5: Inference\n",
        "\n",
        "Convert audio using your trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.inference import VoiceConverter\n",
        "from utils.registry import discover_voices\n",
        "from google.colab import files\n",
        "\n",
        "available_voices = discover_voices(models_dir=\"models\")\n",
        "print(f\"Available models: {available_voices}\")\n",
        "\n",
        "if not available_voices:\n",
        "    print(\"âŒ No trained models found.\")\n",
        "else:\n",
        "    print(\"\\nðŸ“‚ Upload Source Audio (wav/mp3)...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        SOURCE_AUDIO = list(uploaded.keys())[0]\n",
        "        print(f\"   âœ… Source: {SOURCE_AUDIO}\")\n",
        "        \n",
        "        print(\"\\nSelect a model:\")\n",
        "        for idx, v in enumerate(available_voices):\n",
        "            print(f\"{idx}: {v}\")\n",
        "        \n",
        "        try:\n",
        "            selection = int(input(\"Enter number: \"))\n",
        "            TARGET_VOICE = available_voices[selection]\n",
        "        except (ValueError, IndexError):\n",
        "            print(\"âš ï¸ Invalid, defaulting to 0.\")\n",
        "            TARGET_VOICE = available_voices[0]\n",
        "\n",
        "        OUTPUT_PATH = \"/content/output_converted.wav\"\n",
        "        \n",
        "        print(f\"ðŸš€ Converting using '{TARGET_VOICE}'...\")\n",
        "        registry = VoiceRegistry(models_dir=\"models\")\n",
        "        model_path = registry.get_model_path(TARGET_VOICE)\n",
        "        \n",
        "        if model_path:\n",
        "            # Use simple device detection\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            converter = VoiceConverter(model_path, device=device)\n",
        "            try:\n",
        "                converter.convert(SOURCE_AUDIO, OUTPUT_PATH, pitch_shift=0.0)\n",
        "                print(f\"âœ… Done! Saved to: {OUTPUT_PATH}\")\n",
        "                files.download(OUTPUT_PATH)\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Conversion failed: {e}\")\n",
        "        else:\n",
        "            print(f\"âŒ Model path error for {TARGET_VOICE}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}