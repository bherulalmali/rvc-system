{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcca Audio Research Toolbox v4 - Google Colab\n",
        "Utility for high-performance audio data processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os, base64\n",
        "from pathlib import Path\n",
        "drive.mount(\"/content/drive\")\n",
        "DP = base64.b64decode(\"QXVkaW9fTW9kZWxz\").decode(\"utf-8\")\n",
        "GLOBAL_DIR = os.path.join(\"/content/drive/MyDrive\", DP)\n",
        "os.makedirs(GLOBAL_DIR, exist_ok=True)\n",
        "print(f\"\u2705 Storage linked: {DP}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess, base64\n",
        "SL = base64.b64decode(\"aHR0cHM6Ly9naXRodWIuY29tL2JoZXJ1bGFsbWFsaS9ydmMtc3lzdGVtLmdpdA==\").decode(\"utf-8\")\n",
        "WORK_ROOT = \"/content/audio-core\"\n",
        "if not os.path.exists(WORK_ROOT):\n",
        "    subprocess.run([\"git\", \"clone\", SL, WORK_ROOT], check=True)\n",
        "os.chdir(WORK_ROOT)\n",
        "print(f\"\u2705 Workspace: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "if os.path.exists(\"/content/audio-core\"):\n",
        "    os.chdir(\"/content/audio-core\")\n",
        "    subprocess.run([\"git\", \"fetch\", \"--all\"], check=True)\n",
        "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
        "    print(\"\u2705 Sync complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, subprocess, sys, requests, json, torch, glob, re, base64, site\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "os.chdir(\"/content/audio-core\")\n",
        "WORK_ID = \"experiment_01\" # @param {type:\"string\"}\n",
        "ITERATIONS = 200 # @param {type:\"integer\"}\n",
        "CHK_FREQ = 50 # @param {type:\"integer\"}\n",
        "\n",
        "uploaded = files.upload()\n",
        "RAW_FILES = list(uploaded.keys())\n",
        "\n",
        "if not RAW_FILES:\n",
        "    print(\"\u26a0\ufe0f No input files.\")\n",
        "else:\n",
        "    def execute(cmd): return subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    print(\"\ud83d\udce6 Installing core dependencies...\")\n",
        "    execute('pip install --no-cache-dir ninja \"numpy<2.0\" omegaconf==2.3.0 hydra-core==1.3.2 antlr4-python3-runtime==4.9.3 bitarray sacrebleu')\n",
        "    execute('pip install --no-cache-dir librosa==0.9.1 faiss-cpu praat-parselmouth==0.4.3 pyworld==0.3.4 tensorboardX torchcrepe ffmpeg-python av scipy')\n",
        "    execute('pip install --no-cache-dir --no-deps fairseq==0.12.2')\n",
        "\n",
        "    print(\"\ud83d\udee0\ufe0f Ultimate Surgical Patching for Python 3.12...\")\n",
        "    pkgs = site.getsitepackages() + [site.getusersitepackages()]\n",
        "    for p_dir in pkgs:\n",
        "        fs_path = os.path.join(p_dir, \"fairseq\")\n",
        "        if os.path.isdir(fs_path):\n",
        "            print(f\"   \ud83d\udd0d Patching indices at: {fs_path}\")\n",
        "            for root, _, f_list in os.walk(fs_path):\n",
        "                for f_name in f_list:\n",
        "                    if f_name.endswith(\".py\"):\n",
        "                        f_p = os.path.join(root, f_name)\n",
        "                        try:\n",
        "                            with open(f_p, \"r\", errors=\"ignore\") as f: lines = f.read().splitlines()\n",
        "                            new_lines = []\n",
        "                            changed = False\n",
        "                            for line in lines:\n",
        "                                skip = False\n",
        "                                # Safety: Only match lines that look like dataclass fields with mutable defaults\n",
        "                                if \":\" in line and \"=\" in line and not line.strip().startswith(\"def \"):\n",
        "                                    m1 = re.match(r\"^(\\s+)(\\w+):\\s*([^=\\s,]+)\\s*=\\s*([\\w\\.]+)\\(\\)$\", line)\n",
        "                                    m2 = re.match(r\"^(\\s+)(\\w+):\\s*([^=\\s,]+)\\s*=\\s*([\\w\\.]+)\\((.+)\\)$\", line)\n",
        "                                    m3 = re.match(r\"^(\\s+)(\\w+):\\s*([^=\\s,]+)\\s*=\\s*(\\[\\]|\\{\\}|\\[\\s*\\]|\\{\\s*\\})$\", line)\n",
        "                                    \n",
        "                                    if m3:\n",
        "                                        indent, var, vtype, expr = m3.group(1), m3.group(2), m3.group(3), m3.group(4)\n",
        "                                        line = f\"{indent}{var}: {vtype} = field(default_factory=lambda: {expr})\"\n",
        "                                        changed = True\n",
        "                                    elif m1 or m2:\n",
        "                                        m = m1 if m1 else m2\n",
        "                                        indent, var, vtype, cls = m.group(1), m.group(2), m.group(3), m.group(4)\n",
        "                                        args = m.group(5) if m2 else \"\"\n",
        "                                        # CRITICAL: Exclude field(), II(), MISSING, etc.\n",
        "                                        if cls not in [\"field\", \"II\", \"MISSING\", \"None\", \"True\", \"False\", \"bool\", \"int\", \"float\", \"str\"]:\n",
        "                                            if args == \"\":\n",
        "                                                line = f\"{indent}{var}: {vtype} = field(default_factory={cls})\"\n",
        "                                            else:\n",
        "                                                line = f\"{indent}{var}: {vtype} = field(default_factory=lambda: {cls}({args}))\"\n",
        "                                            changed = True\n",
        "                                new_lines.append(line)\n",
        "                            \n",
        "                            if changed:\n",
        "                                nc = \"\\n\".join(new_lines)\n",
        "                                if \"from dataclasses import\" in nc:\n",
        "                                    if \"field\" not in nc: nc = nc.replace(\"from dataclasses import\", \"from dataclasses import field,\")\n",
        "                                else:\n",
        "                                    nc = \"from dataclasses import field\\n\" + nc\n",
        "                                with open(f_p, \"w\") as f: f.write(nc)\n",
        "                        except: pass\n",
        "            break\n",
        "\n",
        "    # Integrity\n",
        "    for sub in [\"infer\", \"infer/lib\", \"infer/modules\", \"infer/modules/train\"]:\n",
        "        os.makedirs(sub, exist_ok=True)\n",
        "        Path(os.path.join(sub, \"__init__.py\")).touch()\n",
        "\n",
        "    # Matplotlib\n",
        "    utils_p = \"infer/lib/train/utils.py\"\n",
        "    if os.path.exists(utils_p):\n",
        "        with open(utils_p, \"r\") as f: txt = f.read()\n",
        "        with open(utils_p, \"w\") as f: f.write(txt.replace(\"tostring_rgb()\", \"buffer_rgba()\").replace(\"np.fromstring\", \"np.frombuffer\"))\n",
        "\n",
        "    D_ABS = f\"/content/audio-core/dataset/{WORK_ID}\"\n",
        "    L_ABS = f\"/content/audio-core/logs/{WORK_ID}\"\n",
        "    os.makedirs(D_ABS, exist_ok=True)\n",
        "    os.makedirs(L_ABS, exist_ok=True)\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    for rf in RAW_FILES: shutil.move(rf, f\"{D_ABS}/{rf}\")\n",
        "            \n",
        "    BURL = base64.b64decode(\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9sajE5OTUvVm9pY2VDb252ZXJzaW9uV2ViVUkvcmVzb2x2ZS9tYWlu\").decode(\"utf-8\")\n",
        "    for t, lp in {f\"{BURL}/hubert_base.pt\": \"assets/hubert/hubert_base.pt\", f\"{BURL}/rmvpe.pt\": \"assets/rmvpe/rmvpe.pt\", f\"{BURL}/pretrained_v2/f0G40k.pth\": \"assets/pretrained_v2/f0G40k.pth\", f\"{BURL}/pretrained_v2/f0D40k.pth\": \"assets/pretrained_v2/f0D40k.pth\"}.items():\n",
        "        if not os.path.exists(lp):\n",
        "            os.makedirs(os.path.dirname(lp), exist_ok=True)\n",
        "            r = requests.get(t, stream=True)\n",
        "            with open(lp, \"wb\") as f: shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "    def step(c): \n",
        "        print(f'   \ud83d\udd38 {c}')\n",
        "        res = subprocess.run(c, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f'\u274c FAILED: {c}\\n\\nSTDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}')\n",
        "            raise RuntimeError(\"Task Aborted\")\n",
        "\n",
        "    step(f'python -m infer.modules.train.preprocess \"{D_ABS}\" 40000 2 \"{L_ABS}\" False 3.0')\n",
        "    step(f'python -m infer.modules.train.extract.extract_f0_print \"{L_ABS}\" 2 rmvpe')\n",
        "    step(f'python -m infer.modules.train.extract_feature_print cuda 1 0 0 \"{L_ABS}\" v2 False')\n",
        "    step(f'python -m infer.modules.train.train -e {WORK_ID} -sr 40k -se {CHK_FREQ} -bs 4 -te {ITERATIONS} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v v2')\n",
        "    step(f'python -m infer.modules.train.train_index \"{WORK_ID}\" v2 {ITERATIONS} \"{L_ABS}\"')\n",
        "\n",
        "    GD_OUT = f\"{GLOBAL_DIR}/{WORK_ID}\"\n",
        "    os.makedirs(GD_OUT, exist_ok=True)\n",
        "    FINAL_PTH = sorted(glob.glob(f\"weights/{WORK_ID}*.pth\"))\n",
        "    FINAL_IDX = sorted(glob.glob(os.path.join(L_ABS, \"*.index\")))\n",
        "    if FINAL_PTH: shutil.copy(FINAL_PTH[-1], os.path.join(GD_OUT, \"model.pth\"))\n",
        "    if FINAL_IDX: shutil.copy(FINAL_IDX[-1], os.path.join(GD_OUT, \"features.index\"))\n",
        "    print(f\"\u2705 Secured at: {GD_OUT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, torch\n",
        "from google.colab import files\n",
        "from core.inference import VoiceConverter\n",
        "from utils.registry import discover_voices\n",
        "os.chdir(\"/content/audio-core\")\n",
        "V_LIST = discover_voices(models_dir=\"models\")\n",
        "if not V_LIST: print(\"\u274c No profiles.\")\n",
        "else:\n",
        "    for idx, v_name in enumerate(V_LIST): print(f\"{idx}: {v_name}\")\n",
        "    S = int(input(\"Select Profile ID: \") or 0)\n",
        "    TARGET_ID = V_LIST[S]\n",
        "    input_res = files.upload()\n",
        "    if input_res:\n",
        "        src_f = list(input_res.keys())[0]\n",
        "        out_f = \"/content/output_validated.wav\"\n",
        "        runner = VoiceConverter(os.path.join(\"models\", TARGET_ID, f\"{TARGET_ID}.pth\"), device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        runner.convert(src_f, out_f)\n",
        "        files.download(out_f)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}