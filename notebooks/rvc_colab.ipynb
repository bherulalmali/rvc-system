{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéß RVC Audio Processor V2 - Google Colab (Python 3.12 Fix)\n",
        "\n",
        "This notebook is specifically hardened for **Python 3.12** and solves all `ModuleNotFoundError`, `NameError`, and `ValueError` (Fairseq) issues.\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  If training fails, run **Step 2.1** to ensure you have the latest fixes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîå Step 1: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Mounting Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/Audio_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"‚úÖ Drive mounted. Models saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# ‚ö†Ô∏è YOUR GITHUB REPO URL ‚ö†Ô∏è\n",
        "REPO_URL = \"https://github.com/bherulalmali/rvc-system.git\"\n",
        "REPO_DIR = \"/content/rvc-system\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository into {REPO_DIR}...\")\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Step 2.1: Update & Reset Fixes\n",
        "\n",
        "Run this if you encounter any code errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_DIR = \"/content/rvc-system\"\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(\"Updating repository and hardening scripts...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"fetch\", \"--all\"], check=True)\n",
        "        subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
        "        print(\"‚úÖ Update and Hard Reset complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Update failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Step 4: Full Pipeline (Preprocessing, Extraction, Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import requests\n",
        "import json\n",
        "import torch\n",
        "import glob\n",
        "import re\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# ================= CONFIGURATION =================\n",
        "os.chdir(\"/content/rvc-system\")\n",
        "PERSON_NAME = \"my_model\" # @param {type:\"string\"}\n",
        "EPOCHS = 200 # @param {type:\"integer\"}\n",
        "SAVE_FREQUENCY = 50 # @param {type:\"integer\"}\n",
        "\n",
        "# 1. Upload Audio\n",
        "print(f\"üé§ Model: {PERSON_NAME}\")\n",
        "print(\"üìÇ Upload .wav files (Dataset)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"‚ö†Ô∏è No files uploaded. Using existing dataset if present.\")\n",
        "else:\n",
        "    # 2. Dependencies\n",
        "    print(\"üì¶ Installing Core Dependencies...\")\n",
        "    def run_cmd(cmd): return subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    run_cmd(\"pip install --no-cache-dir ninja 'numpy<2.0' omegaconf==2.3.0 hydra-core==1.3.2 antlr4-python3-runtime==4.9.3 bitarray sacrebleu\")\n",
        "    run_cmd(\"pip install --no-cache-dir librosa==0.9.1 faiss-cpu praat-parselmouth==0.4.3 pyworld==0.3.4 tensorboardX torchcrepe ffmpeg-python av scipy\")\n",
        "    run_cmd(\"pip install --no-cache-dir --no-deps fairseq==0.12.2\")\n",
        "\n",
        "    # 3. ROOT CAUSE FIX: NUCLEAR FAIRSEQ PATCHER\n",
        "    print(\"üõ†Ô∏è Running Nuclear Python 3.12 Patcher (Guaranteed Fix)...\")\n",
        "    import fairseq\n",
        "    fs_path = os.path.dirname(fairseq.__file__)\n",
        "    for root, _, files_in_dir in os.walk(fs_path):\n",
        "        for f_in_dir in files_in_dir:\n",
        "            if f_in_dir.endswith(\".py\"):\n",
        "                p = os.path.join(root, f_in_dir)\n",
        "                with open(p, \"r\", errors=\"ignore\") as f: c = f.read()\n",
        "                # Regex to find: field_name: Type = Type()\n",
        "                # Replace with: field_name: Type = field(default_factory=Type)\n",
        "                if \"@dataclass\" in c:\n",
        "                    new_c = re.sub(r'(\\b\\w+\\b):\\s*([\\w\\[\\]\\.]+)\\s*=\\s*([\\w\\.]+)\\(\\)', r'\\1: \\2 = field(default_factory=\\3)', c)\n",
        "                    if new_c != c:\n",
        "                        if \"from dataclasses import\" in new_c:\n",
        "                            if \"field\" not in new_c: new_c = new_c.replace(\"from dataclasses import\", \"from dataclasses import field,\")\n",
        "                        else: new_c = \"from dataclasses import field\\n\" + new_c\n",
        "                        with open(p, \"w\") as f: f.write(new_c)\n",
        "                # Fix hydra_init\n",
        "                if \"hydra_init()\" in c:\n",
        "                    with open(p, \"w\") as f: f.write(c.replace(\"hydra_init()\", \"\"))\n",
        "\n",
        "    # 4. Local Fixes\n",
        "    print(\"üõ†Ô∏è Finalizing Local Environment...\")\n",
        "    for d in [\"infer\", \"infer/lib\", \"infer/modules\", \"infer/modules/train\", \"infer/modules/train/extract\"]:\n",
        "        os.makedirs(d, exist_ok=True)\n",
        "        Path(os.path.join(d, \"__init__.py\")).touch()\n",
        "    \n",
        "    up_path = \"infer/lib/train/utils.py\"\n",
        "    if os.path.exists(up_path):\n",
        "        with open(up_path, \"r\") as f: c = f.read()\n",
        "        with open(up_path, \"w\") as f: f.write(c.replace(\"tostring_rgb()\", \"buffer_rgba()\").replace(\"np.fromstring\", \"np.frombuffer\"))\n",
        "\n",
        "    # 5. Execute Pipeline\n",
        "    cwd = os.getcwd()\n",
        "    dataset_abs = f\"{cwd}/dataset/{PERSON_NAME}\"\n",
        "    logs_abs = f\"{cwd}/logs/{PERSON_NAME}\"\n",
        "    \n",
        "    os.makedirs(dataset_abs, exist_ok=True)\n",
        "    os.makedirs(logs_abs, exist_ok=True)\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    \n",
        "    for f in AUDIO_FILES: shutil.move(f, f\"{dataset_abs}/{f}\")\n",
        "\n",
        "    print(\"üß† Starting RVC Engines...\")\n",
        "    def run_rvc_stage(cmd): \n",
        "        res = subprocess.run(cmd, shell=True)\n",
        "        if res.returncode != 0: raise RuntimeError(f\"Stage Failed: {cmd}\")\n",
        "\n",
        "    print(\"--- Stage 1: Preprocess ---\")\n",
        "    run_rvc_stage(f\"python -m infer.modules.train.preprocess '{dataset_abs}' 40000 2 '{logs_abs}' False 3.0\")\n",
        "    \n",
        "    print(\"--- Stage 2: Pitch ---\")\n",
        "    run_rvc_stage(f\"python -m infer.modules.train.extract.extract_f0_print '{logs_abs}' 2 rmvpe\")\n",
        "    \n",
        "    print(\"--- Stage 3: Feature ---\")\n",
        "    run_rvc_stage(f\"python -m infer.modules.train.extract_feature_print cuda 1 0 0 '{logs_abs}' v2 False\")\n",
        "    \n",
        "    print(\"--- Stage 4: Train ---\")\n",
        "    run_rvc_stage(f\"python -m infer.modules.train.train -e {PERSON_NAME} -sr 40k -se {SAVE_FREQUENCY} -bs 4 -te {EPOCHS} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v v2\")\n",
        "    \n",
        "    print(\"--- Stage 5: Index ---\")\n",
        "    run_rvc_stage(f\"python -m infer.modules.train.train_index {PERSON_NAME} v2 {EPOCHS} '{logs_abs}'\")\n",
        "\n",
        "    # 6. Backup\n",
        "    print(\"--- Stage 6: Sync to Drive ---\")\n",
        "    out_dir = f\"{DRIVE_RVC_DIR}/{PERSON_NAME}\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    \n",
        "    pth = sorted(glob.glob(f\"weights/{PERSON_NAME}*.pth\"))\n",
        "    idx = sorted(glob.glob(f\"{logs_abs}/*.index\"))\n",
        "    \n",
        "    if pth: shutil.copy(pth[-1], f\"{out_dir}/{PERSON_NAME}.pth\")\n",
        "    if idx: shutil.copy(idx[-1], f\"{out_dir}/{PERSON_NAME}.index\")\n",
        "    print(f\"‚úÖ SUCCESS! Model backed up to: {out_dir}\")"
      ]
    }
  ],\n  \"metadata\": { \"language_info\": { \"name\": \"python\" } },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 2\n} \n"