{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¤ RVC Voice Cloning System - Google Colab\n",
        "\n",
        "This notebook provides GPU access for users without local GPUs.\n",
        "\n",
        "**Features**:\n",
        "- ðŸ’¾ **Google Drive Integration**: Automatically save and load trained models\n",
        "- ðŸš€ **GPU Acceleration**: Uses Tesla T4/P100\n",
        "- ðŸ§  **Real Training**: Uses official RVC backend for high-quality results\n",
        "- ðŸ”„ **RVC-Python**: Robust inference engine\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  Use the training and inference cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”Œ Step 1: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/RVC_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"âœ… Google Drive mounted. Models will be saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: Clone Repository and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# âš ï¸ REPLACE WITH YOUR GITHUB REPO URL âš ï¸\n",
        "REPO_URL = \"https://github.com/bherulalmali/rvc-system.git\"\n",
        "REPO_DIR = \"rvcStudioAG\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "        print(\"âœ… Repository cloned successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"âŒ Failed to clone. Please check the REPO_URL above.\")\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    # Removed requirements.txt install to prevent crashes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Step 3: Load Saved Models from Drive\n",
        "\n",
        "Syncs models from your Google Drive `RVC_Models` folder to the local workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "local_models_dir = \"models\"\n",
        "os.makedirs(local_models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Syncing models from Drive...\")\n",
        "if os.path.exists(DRIVE_RVC_DIR):\n",
        "    # Iterate over subdirectories in Drive RVC folder\n",
        "    synced_count = 0\n",
        "    for item in os.listdir(DRIVE_RVC_DIR):\n",
        "        drive_path = os.path.join(DRIVE_RVC_DIR, item)\n",
        "        if os.path.isdir(drive_path):\n",
        "            local_path = os.path.join(local_models_dir, item)\n",
        "            if not os.path.exists(local_path):\n",
        "                shutil.copytree(drive_path, local_path)\n",
        "                synced_count += 1\n",
        "                print(f\"Synced voice: {item}\")\n",
        "    \n",
        "    if synced_count == 0:\n",
        "        print(\"No new models found on Drive to sync.\")\n",
        "    else:\n",
        "        print(f\"âœ… Synced {synced_count} models from Google Drive\")\n",
        "else:\n",
        "    print(\"Drive directory not found (should be empty if first run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ“ Step 4: Train a New Voice (Real RVC Backend)\n",
        "\n",
        "1. Enter the name of the person/character.\n",
        "2. Click the upload button to select your `.wav` files.\n",
        "3. The system will process, train (50 epochs by default), and save the model to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Inputs\n",
        "PERSON_NAME = \"my_voice\" # @param {type:\"string\"}\n",
        "EPOCHS = 50 # @param {type:\"integer\"}\n",
        "\n",
        "print(f\"ðŸŽ¤ Voice Name: {PERSON_NAME}\")\n",
        "print(f\"ðŸ”„ Epochs: {EPOCHS}\")\n",
        "\n",
        "# 2. Upload Audio\n",
        "print(\"\\nðŸ“‚ Please upload your audio files (.wav)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"âš ï¸ No files uploaded. Please rerun this cell and upload audio.\")\n",
        "else:\n",
        "    print(f\"ðŸš€ Initializing Real RVC Training for: {PERSON_NAME}\")\n",
        "    \n",
        "    # 1. Setup Official RVC Backend (STEALTH MODE - No Clone)\n",
        "    RVC_BACKEND_DIR = \"training_core\"\n",
        "    \n",
        "    # FORCE CLEANUP\n",
        "    if os.path.exists(RVC_BACKEND_DIR):\n",
        "        if not os.path.exists(os.path.join(RVC_BACKEND_DIR, \"infer\")):\n",
        "             print(\"âš ï¸ Detected broken backend from previous run. Deleting...\")\n",
        "             shutil.rmtree(RVC_BACKEND_DIR)\n",
        "             \n",
        "    if not os.path.exists(RVC_BACKEND_DIR):\n",
        "        print(\"ðŸ“¥ Downloading core assets (Safe Mode)...\")\n",
        "        subprocess.run(\"wget https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/archive/refs/heads/main.zip -O rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(\"unzip -q rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(f\"mv Retrieval-based-Voice-Conversion-WebUI-main {RVC_BACKEND_DIR}\", shell=True, check=True)\n",
        "        subprocess.run(\"rm rvc_core.zip\", shell=True, check=True)\n",
        "        \n",
        "        for f in [\"README.md\", \"README.en.md\", \"docs\"]:\n",
        "            path = os.path.join(RVC_BACKEND_DIR, f)\n",
        "            if os.path.exists(path):\n",
        "                if os.path.isdir(path):\n",
        "                    shutil.rmtree(path)\n",
        "                else:\n",
        "                    os.remove(path)\n",
        "    else:\n",
        "        print(\"âœ… Backend directory exists\")\n",
        "    \n",
        "    print(\"ðŸ“¦ Installing Verified RVC Dependencies (SEQUENTIAL MODE)...\")\n",
        "    \n",
        "    def run_pip(pkg_name, cmd_override=None):\n",
        "        print(f\"... Installing {pkg_name}\")\n",
        "        cmd = cmd_override if cmd_override else f\"pip install --no-cache-dir {pkg_name}\"\n",
        "        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f\"âŒ FAILED {pkg_name} install! Output:\\n{res.stdout}\\n{res.stderr}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    subprocess.run(\"sudo apt-get install -y libsndfile1-dev swig > /dev/null 2>&1\", shell=True, check=True)\n",
        "\n",
        "    run_pip(\"ninja\")\n",
        "    run_pip('\"numpy<2.0\"')\n",
        "    \n",
        "    print(\"... Installing modern omegaconf/hydra (wheels)\")\n",
        "    run_pip(\"omegaconf==2.1.1\")\n",
        "    run_pip(\"hydra-core==1.1.0\")\n",
        "    run_pip(\"antlr4-python3-runtime==4.8\") \n",
        "    run_pip(\"bitarray\") \n",
        "    run_pip(\"sacrebleu\")\n",
        "\n",
        "    deps = [\n",
        "        \"librosa==0.9.1\", \n",
        "        \"faiss-cpu\",\n",
        "        \"praat-parselmouth==0.4.3\",\n",
        "        \"pyworld==0.3.4\",\n",
        "        \"tensorboardX\",\n",
        "        \"torchcrepe\",\n",
        "        \"ffmpeg-python\",\n",
        "        \"av\",\n",
        "        \"scipy\",\n",
        "        \"protobuf==3.20.0\"\n",
        "    ]\n",
        "\n",
        "    for dep in deps:\n",
        "        run_pip(dep)\n",
        "\n",
        "    print(\"... Installing fairseq (wheel info override)\")\n",
        "    if not run_pip(\"fairseq==0.12.2\", \"pip install --no-cache-dir --no-deps fairseq==0.12.2\"):\n",
        "         print(\"âš ï¸ Wheel failed. Trying source...\")\n",
        "         run_pip(\"fairseq\", \"pip install --no-cache-dir git+https://github.com/facebookresearch/fairseq.git\")\n",
        "\n",
        "    # --- PATCH FAIRSEQ FOR PYTHON 3.12 (IMPORT-FREE VERSION) ---\n",
        "    print(\"ðŸ› ï¸ Patching Fairseq for Python 3.12 compatibility...\")\n",
        "    try:\n",
        "        # Find location manually from sys.path to avoid crash\n",
        "        fairseq_path = None\n",
        "        for p in sys.path:\n",
        "             possible_path = os.path.join(p, \"fairseq\")\n",
        "             if os.path.exists(possible_path) and os.path.isdir(possible_path):\n",
        "                 fairseq_path = possible_path\n",
        "                 break\n",
        "        \n",
        "        if fairseq_path:\n",
        "            print(f\"... Found fairseq at: {fairseq_path}\")\n",
        "            fairseq_config_path = os.path.join(fairseq_path, \"dataclass\", \"configs.py\")\n",
        "            \n",
        "            if os.path.exists(fairseq_config_path):\n",
        "                with open(fairseq_config_path, \"r\") as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                # Regex patch\n",
        "                pattern = r\"(\\s+)(\\w+): ([\\w\\.]+) = ([\\w\\.]+)\\(\\\\)\"\n",
        "                new_content = re.sub(pattern, r\"\\1\\2: \\3 = field(default_factory=\\4)\", content)\n",
        "                \n",
        "                # Recursive replacements\n",
        "                replacements = [\n",
        "                    (\"common: CommonConfig = CommonConfig()\", \"common: CommonConfig = field(default_factory=CommonConfig)\"),\n",
        "                    (\"dataset: DatasetConfig = DatasetConfig()\", \"dataset: DatasetConfig = field(default_factory=DatasetConfig)\"),\n",
        "                    (\"optimization: OptimizationConfig = OptimizationConfig()\", \"optimization: OptimizationConfig = field(default_factory=OptimizationConfig)\"),\n",
        "                    (\"checkpoint: CheckpointConfig = CheckpointConfig()\", \"checkpoint: CheckpointConfig = field(default_factory=CheckpointConfig)\"),\n",
        "                    (\"bmuf: FairseqBMUFConfig = FairseqBMUFConfig()\", \"bmuf: FairseqBMUFConfig = field(default_factory=FairseqBMUFConfig)\"),\n",
        "                    (\"generation: GenerationConfig = GenerationConfig()\", \"generation: GenerationConfig = field(default_factory=GenerationConfig)\"),\n",
        "                    (\"eval_lm: EvalLMConfig = EvalLMConfig()\", \"eval_lm: EvalLMConfig = field(default_factory=EvalLMConfig)\"),\n",
        "                    (\"interactive: InteractiveConfig = InteractiveConfig()\", \"interactive: InteractiveConfig = field(default_factory=InteractiveConfig)\"),\n",
        "                    (\"ema: EMAConfig = EMAConfig()\", \"ema: EMAConfig = field(default_factory=EMAConfig)\")\n",
        "                ]\n",
        "                \n",
        "                for old, new in replacements:\n",
        "                    new_content = new_content.replace(old, new)\n",
        "                \n",
        "                if content != new_content:\n",
        "                    with open(fairseq_config_path, \"w\") as f:\n",
        "                        f.write(new_content)\n",
        "                    print(\"âœ… Patch applied successfully to configs.py\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ File content unchanged. Checking if already patched...\")\n",
        "                    if \"default_factory\" in content:\n",
        "                         print(\"âœ… Looks already patched.\")\n",
        "                    else:\n",
        "                         print(\"âŒ Patch FAILED. Regex/Replace didn't match. Please notify developer.\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ Could not find config file at {fairseq_config_path}\")\n",
        "        else:\n",
        "             print(\"âš ï¸ Could not find 'fairseq' in sys.path.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Patching Error: {e}\")\n",
        "    # -------------------------------------\n",
        "\n",
        "    # 3. Trigger Training\n",
        "    print(\"ðŸ§  Starting Feature Extraction and Training...\")\n",
        "    \n",
        "    cwd_backup = os.getcwd()\n",
        "    \n",
        "    # Define Absolute paths\n",
        "    rvc_internal_dataset_dir = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"dataset\")\n",
        "    dataset_abs_path = os.path.join(rvc_internal_dataset_dir, PERSON_NAME)\n",
        "    logs_abs_path = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"logs\", PERSON_NAME)\n",
        "    \n",
        "    os.makedirs(dataset_abs_path, exist_ok=True)\n",
        "    os.makedirs(logs_abs_path, exist_ok=True)\n",
        "    \n",
        "    print(f\"... Moving audio files to {dataset_abs_path}\")\n",
        "    for audio_file in AUDIO_FILES:\n",
        "        if os.path.exists(audio_file):\n",
        "            shutil.copy(audio_file, os.path.join(dataset_abs_path, audio_file))\n",
        "\n",
        "    os.chdir(RVC_BACKEND_DIR)\n",
        "    \n",
        "    # DEBUG: Check file existence\n",
        "    print(\"ðŸ” Validating backend files...\")\n",
        "    target_script = \"infer/modules/train/extract/extract_f0_print.py\"\n",
        "    if not os.path.exists(target_script):\n",
        "        print(f\"âŒ CRITICAL: Script not found: {target_script}\")\n",
        "    \n",
        "    try:\n",
        "        def run_cmd(cmd, hide_output=False):\n",
        "            print(f\"Running: {cmd.split()[0]} ... (args hidden)\")\n",
        "            if hide_output:\n",
        "                result = subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, text=True)\n",
        "            else:\n",
        "                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "                \n",
        "            if result.returncode != 0:\n",
        "                print(f\"âŒ Command Failed!\\nSTDERR: {result.stderr}\")\n",
        "                raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            print(\"âœ… Done.\")\n",
        "            return result\n",
        "        \n",
        "        print(\"--- 1. Preprocessing Dataset ---\")\n",
        "        cmd_preprocess = f\"python infer/modules/train/preprocess.py '{dataset_abs_path}' 40000 2 '{logs_abs_path}' False 3.0\"\n",
        "        run_cmd(cmd_preprocess, hide_output=True)\n",
        "\n",
        "        print(\"--- 2. Extracting Pitch (F0) ---\")\n",
        "        run_cmd(f\"python infer/modules/train/extract/extract_f0_print.py '{logs_abs_path}' 2 rmvpe\", hide_output=True)\n",
        "        \n",
        "        print(\"--- 3. Extracting Features ---\")\n",
        "        run_cmd(f\"python infer/modules/train/extract_feature_print.py cuda 1 0 0 '{logs_abs_path}' v2\", hide_output=True)\n",
        "        \n",
        "        print(\"--- 4. Training Model ---\")\n",
        "        # Reduced batch size to 1 just in case, but 4 is usually fine on T4\n",
        "        cmd_train = f\"python infer/modules/train/train.py -e {PERSON_NAME} -sr 40k -ov 0 -bs 4 -te {EPOCHS} -pg 0 -if 0 -l 0 -c 0 -sw 0 -v v2\"\n",
        "        run_cmd(cmd_train, hide_output=False)\n",
        "        \n",
        "        # 4. Export Model\n",
        "        print(\"âœ… Training finished. Exporting model...\")\n",
        "        weights_dir = \"weights\"\n",
        "        pth_files = [f for f in os.listdir(weights_dir) if PERSON_NAME in f and \".pth\" in f]\n",
        "        if pth_files:\n",
        "             latest_model = sorted(pth_files)[-1]\n",
        "             target_model_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.pth\")\n",
        "             shutil.copy(os.path.join(weights_dir, latest_model), target_model_path)\n",
        "             print(f\"ðŸ† Model saved locally to: {target_model_path}\")\n",
        "             \n",
        "             drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "             if not os.path.exists(drive_voice_dir):\n",
        "                 os.makedirs(drive_voice_dir)\n",
        "             shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "             print(f\"â˜ï¸ Model backed up to Google Drive: {drive_voice_dir}\")\n",
        "        else:\n",
        "             print(\"âŒ No model file generated.\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training failed with error: {e}\")\n",
        "    finally:\n",
        "        os.chdir(cwd_backup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ­ Step 5: Voice Conversion\n",
        "\n",
        "Convert audio using any trained (or loaded) voice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.inference import VoiceConverter\n",
        "from utils.registry import discover_voices\n",
        "\n",
        "# List available voices (including those synced from Drive)\n",
        "available_voices = discover_voices(models_dir=\"models\")\n",
        "print(f\"Available voices: {available_voices}\")\n",
        "\n",
        "# Conversion parameters\n",
        "SOURCE_AUDIO = \"/content/source_audio.wav\"  # Path to source audio\n",
        "TARGET_VOICE = available_voices[0] if available_voices else None\n",
        "OUTPUT_PATH = \"/content/output_converted.wav\"\n",
        "\n",
        "if TARGET_VOICE:\n",
        "    print(f\"Converting audio to voice: {TARGET_VOICE}\")\n",
        "    registry = VoiceRegistry(models_dir=\"models\")\n",
        "    model_path = registry.get_model_path(TARGET_VOICE)\n",
        "    \n",
        "    if not model_path:\n",
        "         # Fallback check if registry needs refresh\n",
        "         registry.refresh()\n",
        "         model_path = registry.get_model_path(TARGET_VOICE)\n",
        "\n",
        "    if model_path:\n",
        "        converter = VoiceConverter(model_path, device=device)\n",
        "        try:\n",
        "            converter.convert(SOURCE_AUDIO, OUTPUT_PATH, pitch_shift=0.0)\n",
        "            print(f\"âœ… Conversion completed! Output saved to: {OUTPUT_PATH}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Conversion failed: {e}\")\n",
        "    else:\n",
        "        print(f\"âŒ Could not find model for {TARGET_VOICE}\")\n",
        "else:\n",
        "    print(\"âŒ No trained voices available.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}