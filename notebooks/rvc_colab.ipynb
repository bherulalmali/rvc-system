{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcca Audio Research Toolbox v4 - Google Colab\n",
        "Utility for high-performance audio data processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os, base64\n",
        "from pathlib import Path\n",
        "drive.mount(\"/content/drive\")\n",
        "DP = base64.b64decode(\"QXVkaW9fTW9kZWxz\").decode(\"utf-8\")\n",
        "GLOBAL_DIR = os.path.join(\"/content/drive/MyDrive\", DP)\n",
        "os.makedirs(GLOBAL_DIR, exist_ok=True)\n",
        "print(f\"\u2705 Storage linked: {DP}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess, base64\n",
        "SL = base64.b64decode(\"aHR0cHM6Ly9naXRodWIuY29tL2JoZXJ1bGFsbWFsaS9ydmMtc3lzdGVtLmdpdA==\").decode(\"utf-8\")\n",
        "WORK_ROOT = \"/content/audio-core\"\n",
        "if not os.path.exists(WORK_ROOT):\n",
        "    subprocess.run([\"git\", \"clone\", SL, WORK_ROOT], check=True)\n",
        "os.chdir(WORK_ROOT)\n",
        "print(f\"\u2705 Workspace: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "if os.path.exists(\"/content/audio-core\"):\n",
        "    os.chdir(\"/content/audio-core\")\n",
        "    subprocess.run([\"git\", \"fetch\", \"--all\"], check=True)\n",
        "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
        "    print(\"\u2705 Sync complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, subprocess, sys, requests, json, torch, glob, re, base64, site, inspect, dataclasses\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "os.chdir(\"/content/audio-core\")\n",
        "WORK_ID = \"experiment_01\" # @param {type:\"string\"}\n",
        "ITERATIONS = 200 # @param {type:\"integer\"}\n",
        "CHK_FREQ = 50 # @param {type:\"integer\"}\n",
        "VERSION = \"v2\" # @param [\"v1\", \"v2\"]\n",
        "SAMPLING_RATE = \"40k\" # @param [\"32k\", \"40k\", \"48k\"]\n",
        "\n",
        "uploaded = files.upload()\n",
        "RAW_FILES = list(uploaded.keys())\n",
        "\n",
        "if not RAW_FILES:\n",
        "    print(\"\u26a0\ufe0f No input files.\")\n",
        "else:\n",
        "    def execute(cmd): return subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    print(\"\ud83d\udce6 Installing environment dependencies...\")\n",
        "    execute('pip install --no-cache-dir ninja \"numpy<2.0\" omegaconf==2.3.0 hydra-core==1.3.2 antlr4-python3-runtime==4.9.3 bitarray sacrebleu')\n",
        "    execute('pip install --no-cache-dir librosa==0.9.1 faiss-cpu praat-parselmouth==0.4.3 pyworld==0.3.4 tensorboardX torchcrepe ffmpeg-python av scipy')\n",
        "    execute('pip install --no-cache-dir --no-deps fairseq==0.12.2')\n",
        "\n",
        "    print(\"\ud83d\udee1\ufe0f Applying Robust System-Level Hardening (Python 3.12)...\")\n",
        "    try:\n",
        "        d_path = inspect.getfile(dataclasses)\n",
        "        with open(d_path, \"r\") as f: content = f.read()\n",
        "        target = \"if f._field_type is _FIELD and f.default.__class__.__hash__ is None:\"\n",
        "        if target in content:\n",
        "            nc = content.replace(target, \"if False: # Fixed by RVC-Colab-Hardening\")\n",
        "            with open(d_path, \"w\") as f: f.write(nc)\n",
        "            print(f\"   \u2705 Legacy mutable defaults legalized: {d_path}\")\n",
        "    except: pass\n",
        "\n",
        "    print(\"\ud83d\udee0\ufe0f Applying Torch 2.6 & Fairseq Hardening...\")\n",
        "    pkgs = site.getsitepackages() + [site.getusersitepackages()]\n",
        "    for p_dir in pkgs:\n",
        "        fs_path = os.path.join(p_dir, \"fairseq\")\n",
        "        if os.path.isdir(fs_path):\n",
        "            cp_util = os.path.join(fs_path, \"checkpoint_utils.py\")\n",
        "            if os.path.exists(cp_util):\n",
        "                try:\n",
        "                    with open(cp_util, \"r\") as f: c = f.read()\n",
        "                    if 'torch.load(f, map_location=torch.device(\"cpu\"))' in c:\n",
        "                        c = c.replace('torch.load(f, map_location=torch.device(\"cpu\"))', 'torch.load(f, map_location=torch.device(\"cpu\"), weights_only=False)')\n",
        "                        with open(cp_util, \"w\") as f: f.write(c)\n",
        "                except: pass\n",
        "            \n",
        "            for root, _, f_list in os.walk(fs_path):\n",
        "                for f_name in f_list:\n",
        "                    f_p = os.path.join(root, f_name)\n",
        "                    if f_name == \"initialize.py\" and \"dataclass\" in root:\n",
        "                        try:\n",
        "                            with open(f_p, \"r\") as f: c = f.read()\n",
        "                            if \"cs.store(name=k, node=v)\" in c:\n",
        "                                nc = re.sub(r\"^(\\s+)(cs\\.store\\(name=k, node=v\\))$\", r\"\\1try: \\2\\n\\1except: pass\", c, flags=re.M)\n",
        "                                if nc != c: with open(f_p, \"w\") as f: f.write(nc)\n",
        "                        except: pass\n",
        "                    if f_name == \"__init__.py\" and root.endswith(\"fairseq\"):\n",
        "                        try:\n",
        "                            with open(f_p, \"r\") as f: c = f.read()\n",
        "                            if \"hydra_init()\" in c and \"try:\" not in c:\n",
        "                                nc = c.replace(\"hydra_init()\", \"try: hydra_init()\\nexcept: pass\")\n",
        "                                if nc != c: with open(f_p, \"w\") as f: f.write(nc)\n",
        "                        except: pass\n",
        "            break\n",
        "\n",
        "    # Patch RVC Entry Points\n",
        "    for rp in [\"infer/modules/train/extract_feature_print.py\", \"infer/lib/train/utils.py\", \"infer/modules/train/train.py\"]:\n",
        "        if os.path.exists(rp):\n",
        "            try:\n",
        "                with open(rp, \"r\") as f: c = f.read()\n",
        "                if \"torch.load(\" in c and \"weights_only\" not in c:\n",
        "                    nc = re.sub(r\"(torch\\.load\\([^)]+)(\\))\", r\"\\1, weights_only=False\\2\", c)\n",
        "                    with open(rp, \"w\") as f: f.write(nc)\n",
        "            except: pass\n",
        "\n",
        "    # Matplotlib fix\n",
        "    utils_p = \"infer/lib/train/utils.py\"\n",
        "    if os.path.exists(utils_p):\n",
        "        try:\n",
        "            with open(utils_p, \"r\") as f: txt = f.read()\n",
        "            with open(utils_p, \"w\") as f: f.write(txt.replace(\"tostring_rgb()\", \"buffer_rgba()\").replace(\"np.fromstring\", \"np.frombuffer\"))\n",
        "        except: pass\n",
        "\n",
        "    # Integrity\n",
        "    for sub in [\"infer\", \"infer/lib\", \"infer/modules\", \"infer/modules/train\"]:\n",
        "        os.makedirs(sub, exist_ok=True)\n",
        "        Path(os.path.join(sub, \"__init__.py\")).touch()\n",
        "\n",
        "    D_ABS = f\"/content/audio-core/dataset/{WORK_ID}\"\n",
        "    L_ABS = f\"/content/audio-core/logs/{WORK_ID}\"\n",
        "    os.makedirs(D_ABS, exist_ok=True)\n",
        "    os.makedirs(L_ABS, exist_ok=True)\n",
        "    for rf in RAW_FILES: shutil.move(rf, f\"{D_ABS}/{rf}\")\n",
        "    \n",
        "    # SETUP CONFIG.JSON\n",
        "    CFG_SRC = f\"configs/{VERSION}/{SAMPLING_RATE}.json\"\n",
        "    if os.path.exists(CFG_SRC):\n",
        "        shutil.copy(CFG_SRC, f\"{L_ABS}/config.json\")\n",
        "        print(f\"   \u2705 Training config linked: {CFG_SRC}\")\n",
        "    else:\n",
        "        print(f\"   \u26a0\ufe0f Config {CFG_SRC} not found. Training might fail.\")\n",
        "            \n",
        "    BURL = base64.b64decode(\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9sajE5OTUvVm9pY2VDb252ZXJzaW9uV2ViVUkvcmVzb2x2ZS9tYWlu\").decode(\"utf-8\")\n",
        "    for t, lp in {f\"{BURL}/hubert_base.pt\": f\"assets/hubert/hubert_base.pt\", f\"{BURL}/rmvpe.pt\": f\"assets/rmvpe/rmvpe.pt\", f\"{BURL}/pretrained_v2/f0G40k.pth\": f\"assets/pretrained_v2/f0G40k.pth\", f\"{BURL}/pretrained_v2/f0D40k.pth\": f\"assets/pretrained_v2/f0D40k.pth\"}.items():\n",
        "        if not os.path.exists(lp):\n",
        "            os.makedirs(os.path.dirname(lp), exist_ok=True)\n",
        "            r = requests.get(t, stream=True)\n",
        "            with open(lp, \"wb\") as f: shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "    def step(c): \n",
        "        print(f'   \ud83d\udd38 {c}')\n",
        "        res = subprocess.run(c, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f'\u274c FAILED: {c}\\n\\nSTDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}')\n",
        "            raise RuntimeError(\"Task Aborted\")\n",
        "\n",
        "    # Pipeline Execution\n",
        "    SR_VAL = SAMPLING_RATE.replace(\"k\", \"000\")\n",
        "    step(f'python -m infer.modules.train.preprocess \"{D_ABS}\" {SR_VAL} 2 \"{L_ABS}\" False 3.0')\n",
        "    step(f'python -m infer.modules.train.extract.extract_f0_print \"{L_ABS}\" 2 rmvpe')\n",
        "    step(f'python -m infer.modules.train.extract_feature_print cuda 1 0 0 \"{L_ABS}\" {VERSION} False')\n",
        "    step(f'python -m infer.modules.train.train -e \"{WORK_ID}\" -sr {SAMPLING_RATE} -se {CHK_FREQ} -bs 4 -te {ITERATIONS} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v {VERSION}')\n",
        "    step(f'python -m infer.modules.train.train_index \"{WORK_ID}\" {VERSION} {ITERATIONS} \"{L_ABS}\"')\n",
        "\n",
        "    GD_OUT = f\"{GLOBAL_DIR}/{WORK_ID}\"\n",
        "    os.makedirs(GD_OUT, exist_ok=True)\n",
        "    # Search aggressively for trained weight\n",
        "    FINAL_PTH = sorted(glob.glob(f\"weights/{WORK_ID}*.pth\") + glob.glob(f\"**/weights/{WORK_ID}*.pth\", recursive=True))\n",
        "    FINAL_IDX = sorted(glob.glob(f\"{L_ABS}/*.index\"))\n",
        "    if FINAL_PTH:\n",
        "        shutil.copy(FINAL_PTH[-1], os.path.join(GD_OUT, \"model.pth\"))\n",
        "        print(f\"   \ud83d\udcbe Saved weight: {FINAL_PTH[-1]} -> {GD_OUT}/model.pth\")\n",
        "    if FINAL_IDX:\n",
        "        shutil.copy(FINAL_IDX[-1], os.path.join(GD_OUT, \"features.index\"))\n",
        "        print(f\"   \ud83d\udcbe Saved index: {FINAL_IDX[-1]} -> {GD_OUT}/features.index\")\n",
        "    print(f\"\u2705 Secured at: {GD_OUT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, torch, glob, base64\n",
        "from google.colab import files\n",
        "from core.inference import VoiceConverter\n",
        "\n",
        "os.chdir(\"/content/audio-core\")\n",
        "DP = base64.b64decode(\"QXVkaW9fTW9kZWxz\").decode(\"utf-8\")\n",
        "GLOBAL_DIR = os.path.join(\"/content/drive/MyDrive\", DP)\n",
        "\n",
        "print(\"\ud83d\udd0d Scanning for models...\")\n",
        "MODELS = []\n",
        "# Locations to scan\n",
        "SCAN_PATHS = [\"weights\", \"assets/weights\", \"models\", GLOBAL_DIR]\n",
        "\n",
        "for s_path in SCAN_PATHS:\n",
        "    if os.path.exists(s_path):\n",
        "        for root, _, files_list in os.walk(s_path):\n",
        "            for f in files_list:\n",
        "                if f.endswith(\".pth\") or f == \"model.pth\":\n",
        "                    full_p = os.path.abspath(os.path.join(root, f))\n",
        "                    # Label construction\n",
        "                    prefix = \"[Drive]\" if GLOBAL_DIR in full_p else \"[Local]\"\n",
        "                    rel = os.path.relpath(full_p, s_path) if s_path != GLOBAL_DIR else os.path.basename(os.path.dirname(full_p))\n",
        "                    MODELS.append({\"name\": f\"{prefix} {rel}/{f}\", \"path\": full_p})\n",
        "\n",
        "# Remove duplicates\n",
        "seen = {m['path'] for m in []}\n",
        "UNIQUE_MODELS = []\n",
        "for m in MODELS:\n",
        "    if m['path'] not in seen:\n",
        "        UNIQUE_MODELS.append(m)\n",
        "        seen.add(m['path'])\n",
        "\n",
        "if not UNIQUE_MODELS:\n",
        "    print(\"\u274c No models automatically detected.\")\n",
        "    MANUAL_PATH = input(\"Please enter absolute path to model.pth manually: \")\n",
        "    if os.path.exists(MANUAL_PATH):\n",
        "        SELECTED_PATH = MANUAL_PATH\n",
        "        VOICE_NAME = \"manual_voice\"\n",
        "    else:\n",
        "        print(\"\ud83d\uded1 Error: Manual path does not exist.\")\n",
        "        SELECTED_PATH = None\n",
        "else:\n",
        "    for idx, m in enumerate(UNIQUE_MODELS): print(f\"{idx}: {m['name']}\")\n",
        "    choice = input(\"Select Model ID (or enter absolute path): \")\n",
        "    if choice.isdigit() and int(choice) < len(UNIQUE_MODELS):\n",
        "        SELECTED_PATH = UNIQUE_MODELS[int(choice)]['path']\n",
        "    elif os.path.exists(choice):\n",
        "        SELECTED_PATH = choice\n",
        "    else:\n",
        "        SELECTED_PATH = UNIQUE_MODELS[0]['path']\n",
        "        print(f\"\u26a0\ufe0f Invalid choice, defaulting to: {SELECTED_PATH}\")\n",
        "\n",
        "if SELECTED_PATH:\n",
        "    print(f\"\ud83c\udfaf Ready: {SELECTED_PATH}\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        src_f = list(uploaded.keys())[0]\n",
        "        out_f = f\"/content/output_{os.path.basename(src_f)}\"\n",
        "        print(f\"\ud83e\ude84 Converting {src_f}...\")\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        runner = VoiceConverter(SELECTED_PATH, device=device)\n",
        "        runner.convert(src_f, out_f)\n",
        "        files.download(out_f)\n",
        "        print(f\"\u2705 Conversion complete: {out_f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}