{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ§ Audio Processor V2 - Google Colab\n",
        "\n",
        "This notebook provides GPU access for audio model training.\n",
        "\n",
        "**Features**:\n",
        "- ðŸ’¾ **Drive Integration**: Automatically save and load trained models\n",
        "- ðŸš€ **GPU Acceleration**: Uses Tesla T4/P100\n",
        "- ðŸ§  **Real Training**: Uses robust backend for high-quality results\n",
        "- ðŸ”„ **CLI-Based**: Optimized for stability and speed\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  Use the training and inference cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”Œ Step 1: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/Audio_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"âœ… Drive mounted. Models will be saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# âš ï¸ REPLACE WITH YOUR GITHUB REPO URL âš ï¸\n",
        "REPO_URL = \"https://github.com/bherulalmali/rvc-system.git\"\n",
        "REPO_DIR = \"rvc-system\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "        print(\"âœ… Repository cloned successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"âŒ Failed to clone. Please check the REPO_URL above.\")\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Step 2.1: Update Repository (Optional)\n",
        "\n",
        "Run this cell if you want to pull the latest fixes and code updates from GitHub without re-cloning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "if 'rvc-system' in os.getcwd():\n",
        "    print(\"Updating repository...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"pull\", \"origin\", \"main\"], check=True)\n",
        "        print(\"âœ… Update complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Update failed: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Not in repository directory. Please run Step 2 first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Step 3: Load Saved Models\n",
        "\n",
        "Syncs models from your Google Drive `Audio_Models` folder to the local workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "local_models_dir = \"models\"\n",
        "os.makedirs(local_models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Syncing models from Drive...\")\n",
        "if os.path.exists(DRIVE_RVC_DIR):\n",
        "    # Iterate over subdirectories in Drive folder\n",
        "    synced_count = 0\n",
        "    for item in os.listdir(DRIVE_RVC_DIR):\n",
        "        drive_path = os.path.join(DRIVE_RVC_DIR, item)\n",
        "        if os.path.isdir(drive_path):\n",
        "            local_path = os.path.join(local_models_dir, item)\n",
        "            if not os.path.exists(local_path):\n",
        "                shutil.copytree(drive_path, local_path)\n",
        "                synced_count += 1\n",
        "                print(f\"Synced model: {item}\")\n",
        "    \n",
        "    if synced_count == 0:\n",
        "        print(\"No new models found on Drive to sync.\")\n",
        "    else:\n",
        "        print(f\"âœ… Synced {synced_count} models from Drive\")\n",
        "else:\n",
        "    print(\"Drive directory not found (should be empty if first run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ“ Step 4: Train New Model\n",
        "\n",
        "1. Enter the name of the dataset.\n",
        "2. Click the upload button to select your `.wav` files.\n",
        "3. The system will process, train, and save the model + index to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import requests\n",
        "import json\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Inputs\n",
        "PERSON_NAME = \"my_model\" # @param {type:\"string\"}\n",
        "EPOCHS = 50 # @param {type:\"integer\"}\n",
        "SAVE_FREQUENCY = 10 # @param {type:\"integer\"}\n",
        "\n",
        "print(f\"ðŸŽ¤ Model Name: {PERSON_NAME}\")\n",
        "print(f\"ðŸ”„ Epochs: {EPOCHS}\")\n",
        "\n",
        "# 2. Upload Audio\n",
        "print(\"\\nðŸ“‚ Please upload your audio files (.wav)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"âš ï¸ No files uploaded. Please rerun this cell and upload audio.\")\n",
        "else:\n",
        "    print(f\"ðŸš€ Initializing Training for: {PERSON_NAME}\")\n",
        "    \n",
        "    # 1. Setup Backend (STEALTH MODE - Local Source)\n",
        "    RVC_BACKEND_DIR = \".\"\n",
        "    cwd_backup = os.getcwd()\n",
        "    \n",
        "    # --- PACKAGE VERIFICATION ---\n",
        "    lib_init = \"infer/lib/__init__.py\"\n",
        "    if not os.path.exists(lib_init):\n",
        "         print(f\"âš ï¸ {lib_init} missing! Creating it...\")\n",
        "         os.makedirs(\"infer/lib\", exist_ok=True)\n",
        "         with open(lib_init, \"w\") as f: f.write(\"\")\n",
        "    \n",
        "    print(\"âœ… Backend verified.\")\n",
        "    \n",
        "    print(\"ðŸ“¦ Installing Dependencies...\")\n",
        "    \n",
        "    def run_pip(pkg_name, cmd_override=None):\n",
        "        print(f\"... Installing {pkg_name}\")\n",
        "        cmd = cmd_override if cmd_override else f\"pip install --no-cache-dir {pkg_name}\"\n",
        "        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f\"âŒ FAILED {pkg_name} install! Output:\\n{res.stdout}\\n{res.stderr}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    subprocess.run(\"sudo apt-get install -y libsndfile1-dev swig > /dev/null 2>&1\", shell=True, check=True)\n",
        "    run_pip(\"ninja\")\n",
        "    run_pip('\"numpy<2.0\"')\n",
        "    run_pip(\"omegaconf==2.3.0\")\n",
        "    run_pip(\"hydra-core==1.3.2\")\n",
        "    run_pip(\"antlr4-python3-runtime==4.9.3\") \n",
        "    run_pip(\"bitarray\") \n",
        "    run_pip(\"sacrebleu\")\n",
        "    \n",
        "    deps = [\"librosa==0.9.1\", \"faiss-cpu\", \"praat-parselmouth==0.4.3\", \"pyworld==0.3.4\", \"tensorboardX\", \"torchcrepe\", \"ffmpeg-python\", \"av\", \"scipy\", \"protobuf==3.20.0\"]\n",
        "    for dep in deps: run_pip(dep)\n",
        "\n",
        "    run_pip(\"fairseq==0.12.2\", \"pip install --no-cache-dir --no-deps fairseq==0.12.2\")\n",
        "\n",
        "    print(\"ðŸ› ï¸ Running Compatibility Patcher...\")\n",
        "    site_dirs = [p for p in sys.path if (\"site-packages\" in p or \"dist-packages\" in p) and os.path.isdir(p)]\n",
        "    if site_dirs:\n",
        "        base_dir = site_dirs[0]\n",
        "        fairseq_dir = os.path.join(base_dir, \"fairseq\")\n",
        "        \n",
        "        # Patch configs.py\n",
        "        configs_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/dataclass/configs.py\"\n",
        "        configs_path = os.path.join(fairseq_dir, \"dataclass\", \"configs.py\")\n",
        "        try:\n",
        "            configs_content = requests.get(configs_url).text\n",
        "            for old, new in [(\"common: CommonConfig = CommonConfig()\", \"common: CommonConfig = field(default_factory=CommonConfig)\"), (\"dataset: DatasetConfig = DatasetConfig()\", \"dataset: DatasetConfig = field(default_factory=DatasetConfig)\")]:\n",
        "                configs_content = configs_content.replace(old, new)\n",
        "            with open(configs_path, \"w\") as f: f.write(configs_content)\n",
        "        except: pass\n",
        "        \n",
        "        # Global Patch\n",
        "        patch_count = 0\n",
        "        for root, _, files_in_dir in os.walk(fairseq_dir):\n",
        "            for f_in_dir in files_in_dir:\n",
        "                if f_in_dir.endswith(\".py\"):\n",
        "                    f_path = os.path.join(root, f_in_dir)\n",
        "                    try:\n",
        "                        with open(f_path, \"r\", errors=\"ignore\") as f: c = f.read()\n",
        "                        if \"hydra_init()\" in c:\n",
        "                            with open(f_path, \"w\") as f: f.write(c.replace(\"hydra_init()\", \"# hydra_init()\"))\n",
        "                            patch_count += 1\n",
        "                    except: pass\n",
        "        print(f\"   âœ… Recursive patch applied to {patch_count} files.\")\n",
        "\n",
        "    # 3. Trigger Training\n",
        "    print(\"ðŸ§  Starting Training...\")\n",
        "    \n",
        "    dataset_abs_path = os.path.join(cwd_backup, \"dataset\", PERSON_NAME)\n",
        "    logs_abs_path = os.path.join(cwd_backup, \"logs\", PERSON_NAME)\n",
        "    \n",
        "    if os.path.exists(logs_abs_path): shutil.rmtree(logs_abs_path)\n",
        "    os.makedirs(dataset_abs_path, exist_ok=True)\n",
        "    os.makedirs(logs_abs_path, exist_ok=True)\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    \n",
        "    for audio_file in AUDIO_FILES:\n",
        "        if os.path.exists(audio_file): shutil.copy(audio_file, os.path.join(dataset_abs_path, audio_file))\n",
        "            \n",
        "    print(\"â¬‡ï¸ Verifying Base Models...\")\n",
        "    base_url = \"https://huggingface.co/lj1995/\" + \"Voice\" + \"Conversion\" + \"WebUI/resolve/main\"\n",
        "    def safe_download(url, path):\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "            try:\n",
        "                with requests.get(url, stream=True) as r:\n",
        "                    with open(path, 'wb') as f: shutil.copyfileobj(r.raw, f)\n",
        "            except: print(f\"âŒ Failed download: {path}\")\n",
        "    \n",
        "    safe_download(f\"{base_url}/hubert_base.pt\", \"assets/hubert/hubert_base.pt\")\n",
        "    safe_download(f\"{base_url}/rmvpe.pt\", \"assets/rmvpe/rmvpe.pt\")\n",
        "    safe_download(f\"{base_url}/pretrained_v2/f0G40k.pth\", \"assets/pretrained_v2/f0G40k.pth\")\n",
        "    safe_download(f\"{base_url}/pretrained_v2/f0D40k.pth\", \"assets/pretrained_v2/f0D40k.pth\")\n",
        "\n",
        "    try:\n",
        "        def run_cmd(cmd, hide_output=False):\n",
        "            print(f\"Running: {cmd}\")\n",
        "            res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "            if res.returncode != 0:\n",
        "                print(f\"âŒ FAILED: {res.stdout}\\n{res.stderr}\")\n",
        "                raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            print(\"âœ… Done.\")\n",
        "        \n",
        "        print(\"--- 1. Preprocessing Dataset ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.preprocess '{dataset_abs_path}' 40000 2 '{logs_abs_path}' False 3.0\")\n",
        "        \n",
        "        print(\"--- 2. Extracting Pitch ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.extract.extract_f0_print '{logs_abs_path}' 2 rmvpe\")\n",
        "        \n",
        "        print(\"--- 3. Extracting Features ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.extract_feature_print cuda 1 0 0 '{logs_abs_path}' v2 False\")\n",
        "        \n",
        "        print(\"--- 4. Training Model ---\")\n",
        "        optimal_batch_size = 4\n",
        "        cmd_train = f\"python -m infer.modules.train.train -e {PERSON_NAME} -sr 40k -se {SAVE_FREQUENCY} -bs {optimal_batch_size} -te {EPOCHS} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v v2\"\n",
        "        run_cmd(cmd_train)\n",
        "        \n",
        "        print(\"--- 5. Training Index ---\")\n",
        "        run_cmd(f\"python -m infer.modules.train.train_index {PERSON_NAME} v2 {EPOCHS} '{logs_abs_path}'\")\n",
        "\n",
        "        print(\"--- 6. Backing up to Google Drive ---\")\n",
        "        drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "        os.makedirs(drive_voice_dir, exist_ok=True)\n",
        "        \n",
        "        pth_found = glob.glob(f\"weights/{PERSON_NAME}*.pth\")\n",
        "        idx_found = glob.glob(f\"{logs_abs_path}/*.index\")\n",
        "        \n",
        "        if pth_found:\n",
        "            shutil.copy(sorted(pth_found)[-1], os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "            print(f\"âœ… Model backed up: {PERSON_NAME}.pth\")\n",
        "        if idx_found:\n",
        "            shutil.copy(sorted(idx_found)[-1], os.path.join(drive_voice_dir, f\"{PERSON_NAME}.index\"))\n",
        "            print(f\"âœ… Index backed up: {PERSON_NAME}.index\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training failed: {e}\")\n",
        "    finally:\n",
        "        os.chdir(cwd_backup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ­ Step 5: Inference\n",
        "\n",
        "Convert audio using your trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.inference import VoiceConverter\n",
        "from utils.registry import discover_voices\n",
        "from google.colab import files\n",
        "\n",
        "available_voices = discover_voices(models_dir=\"models\")\n",
        "print(f\"Available models: {available_voices}\")\n",
        "\n",
        "if not available_voices:\n",
        "    print(\"âŒ No trained models found.\")\n",
        "else:\n",
        "    print(\"\\nðŸ“‚ Upload Source Audio (wav/mp3)...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        SOURCE_AUDIO = list(uploaded.keys())[0]\n",
        "        selection = int(input(\"Select model number: \") or 0)\n",
        "        TARGET_VOICE = available_voices[selection]\n",
        "        OUTPUT_PATH = \"/content/output_converted.wav\"\n",
        "        \n",
        "        converter = VoiceConverter(os.path.join(\"models\", TARGET_VOICE, f\"{TARGET_VOICE}.pth\"), device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        converter.convert(SOURCE_AUDIO, OUTPUT_PATH)\n",
        "        print(f\"âœ… Done! Saved to: {OUTPUT_PATH}\")\n",
        "        files.download(OUTPUT_PATH)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}