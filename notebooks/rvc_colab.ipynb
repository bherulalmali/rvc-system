{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¤ RVC Voice Cloning System - Google Colab\n",
        "\n",
        "This notebook provides GPU access for users without local GPUs.\n",
        "\n",
        "**Features**:\n",
        "- ðŸ’¾ **Google Drive Integration**: Automatically save and load trained models\n",
        "- ðŸš€ **GPU Acceleration**: Uses Tesla T4/P100\n",
        "- ðŸ§  **Real Training**: Uses official RVC backend for high-quality results\n",
        "- ðŸ”„ **RVC-Python**: Robust inference engine\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  Use the training and inference cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”Œ Step 1: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/RVC_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"âœ… Google Drive mounted. Models will be saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: Clone Repository and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# âš ï¸ REPLACE WITH YOUR GITHUB REPO URL âš ï¸\n",
        "REPO_URL = \"https://github.com/bherulalmali/rvc-system.git\"\n",
        "REPO_DIR = \"rvcStudioAG\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "        print(\"âœ… Repository cloned successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"âŒ Failed to clone. Please check the REPO_URL above.\")\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    # Removed requirements.txt install to prevent crashes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”„ Step 3: Load Saved Models from Drive\n",
        "\n",
        "Syncs models from your Google Drive `RVC_Models` folder to the local workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "local_models_dir = \"models\"\n",
        "os.makedirs(local_models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Syncing models from Drive...\")\n",
        "if os.path.exists(DRIVE_RVC_DIR):\n",
        "    # Iterate over subdirectories in Drive RVC folder\n",
        "    synced_count = 0\n",
        "    for item in os.listdir(DRIVE_RVC_DIR):\n",
        "        drive_path = os.path.join(DRIVE_RVC_DIR, item)\n",
        "        if os.path.isdir(drive_path):\n",
        "            local_path = os.path.join(local_models_dir, item)\n",
        "            if not os.path.exists(local_path):\n",
        "                shutil.copytree(drive_path, local_path)\n",
        "                synced_count += 1\n",
        "                print(f\"Synced voice: {item}\")\n",
        "    \n",
        "    if synced_count == 0:\n",
        "        print(\"No new models found on Drive to sync.\")\n",
        "    else:\n",
        "        print(f\"âœ… Synced {synced_count} models from Google Drive\")\n",
        "else:\n",
        "    print(\"Drive directory not found (should be empty if first run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ“ Step 4: Train a New Voice (Real RVC Backend)\n",
        "\n",
        "1. Enter the name of the person/character.\n",
        "2. Click the upload button to select your `.wav` files.\n",
        "3. The system will process, train (50 epochs by default), and save the model to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Inputs\n",
        "PERSON_NAME = \"my_voice\" # @param {type:\"string\"}\n",
        "EPOCHS = 50 # @param {type:\"integer\"}\n",
        "\n",
        "print(f\"ðŸŽ¤ Voice Name: {PERSON_NAME}\")\n",
        "print(f\"ðŸ”„ Epochs: {EPOCHS}\")\n",
        "\n",
        "# 2. Upload Audio\n",
        "print(\"\\nðŸ“‚ Please upload your audio files (.wav)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"âš ï¸ No files uploaded. Please rerun this cell and upload audio.\")\n",
        "else:\n",
        "    print(f\"ðŸš€ Initializing Real RVC Training for: {PERSON_NAME}\")\n",
        "    \n",
        "    # 1. Setup Official RVC Backend (STEALTH MODE - No Clone)\n",
        "    RVC_BACKEND_DIR = \"training_core\"\n",
        "    \n",
        "    # FORCE CLEANUP\n",
        "    if os.path.exists(RVC_BACKEND_DIR):\n",
        "        if not os.path.exists(os.path.join(RVC_BACKEND_DIR, \"infer\")):\n",
        "             print(\"âš ï¸ Detected broken backend from previous run. Deleting...\")\n",
        "             shutil.rmtree(RVC_BACKEND_DIR)\n",
        "             \n",
        "    if not os.path.exists(RVC_BACKEND_DIR):\n",
        "        print(\"ðŸ“¥ Downloading core assets (Safe Mode)...\")\n",
        "        subprocess.run(\"wget https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/archive/refs/heads/main.zip -O rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(\"unzip -q rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(f\"mv Retrieval-based-Voice-Conversion-WebUI-main {RVC_BACKEND_DIR}\", shell=True, check=True)\n",
        "        subprocess.run(\"rm rvc_core.zip\", shell=True, check=True)\n",
        "        \n",
        "        for f in [\"README.md\", \"README.en.md\", \"docs\"]:\n",
        "            path = os.path.join(RVC_BACKEND_DIR, f)\n",
        "            if os.path.exists(path):\n",
        "                if os.path.isdir(path):\n",
        "                    shutil.rmtree(path)\n",
        "                else:\n",
        "                    os.remove(path)\n",
        "    else:\n",
        "        print(\"âœ… Backend directory exists\")\n",
        "    \n",
        "    print(\"ðŸ“¦ Installing Verified RVC Dependencies (SEQUENTIAL MODE)...\")\n",
        "    \n",
        "    def run_pip(pkg_name, cmd_override=None):\n",
        "        print(f\"... Installing {pkg_name}\")\n",
        "        cmd = cmd_override if cmd_override else f\"pip install --no-cache-dir {pkg_name}\"\n",
        "        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f\"âŒ FAILED {pkg_name} install! Output:\\n{res.stdout}\\n{res.stderr}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    subprocess.run(\"sudo apt-get install -y libsndfile1-dev swig > /dev/null 2>&1\", shell=True, check=True)\n",
        "\n",
        "    run_pip(\"ninja\")\n",
        "    run_pip('\"numpy<2.0\"')\n",
        "    \n",
        "    # Use modern Hydra/Omegaconf for Python 3.12 support\n",
        "    print(\"... Installing modern omegaconf/hydra (wheels)\")\n",
        "    run_pip(\"omegaconf==2.3.0\")\n",
        "    run_pip(\"hydra-core==1.3.2\")\n",
        "    run_pip(\"antlr4-python3-runtime==4.9.3\") \n",
        "    run_pip(\"bitarray\") \n",
        "    run_pip(\"sacrebleu\")\n",
        "\n",
        "    deps = [\n",
        "        \"librosa==0.9.1\", \n",
        "        \"faiss-cpu\",\n",
        "        \"praat-parselmouth==0.4.3\",\n",
        "        \"pyworld==0.3.4\",\n",
        "        \"tensorboardX\",\n",
        "        \"torchcrepe\",\n",
        "        \"ffmpeg-python\",\n",
        "        \"av\",\n",
        "        \"scipy\",\n",
        "        \"protobuf==3.20.0\"\n",
        "    ]\n",
        "\n",
        "    for dep in deps:\n",
        "        run_pip(dep)\n",
        "\n",
        "    print(\"... Installing fairseq (wheel info override)\")\n",
        "    if not run_pip(\"fairseq==0.12.2\", \"pip install --no-cache-dir --no-deps fairseq==0.12.2\"):\n",
        "         print(\"âš ï¸ Wheel failed. Trying source...\")\n",
        "         run_pip(\"fairseq\", \"pip install --no-cache-dir git+https://github.com/facebookresearch/fairseq.git\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # ðŸ PYTHON 3.12 COMPATIBILITY PATCHER (SAFE REGEX MODE)\n",
        "    # ==========================================================================\n",
        "    print(\"ðŸ› ï¸ Running Python 3.12 Compatibility Patcher (Safe Regex Mode)...\")\n",
        "    \n",
        "    site_dirs = [p for p in sys.path if (\"site-packages\" in p or \"dist-packages\" in p) and os.path.isdir(p)]\n",
        "    if not site_dirs:\n",
        "        print(\"âŒ Could not locate package directory!\")\n",
        "    else:\n",
        "        base_dir = site_dirs[0]\n",
        "        fairseq_dir = os.path.join(base_dir, \"fairseq\")\n",
        "        \n",
        "        # --- PART A: Manual Fix for known critical file (configs.py) ---\n",
        "        configs_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/dataclass/configs.py\"\n",
        "        configs_path = os.path.join(fairseq_dir, \"dataclass\", \"configs.py\")\n",
        "        \n",
        "        try:\n",
        "            print(\"   â¬‡ï¸ Downloading pristine configs.py...\")\n",
        "            configs_content = requests.get(configs_url).text\n",
        "            \n",
        "            print(\"   ðŸ”§ Applying Python 3.12 mutable default fixes (Part A)...\")\n",
        "            replacements = [\n",
        "                 (\"common: CommonConfig = CommonConfig()\", \"common: CommonConfig = field(default_factory=CommonConfig)\"),\n",
        "                 (\"dataset: DatasetConfig = DatasetConfig()\", \"dataset: DatasetConfig = field(default_factory=DatasetConfig)\"),\n",
        "                 (\"distributed_training: DistributedTrainingConfig = DistributedTrainingConfig()\", \"distributed_training: DistributedTrainingConfig = field(default_factory=DistributedTrainingConfig)\"),\n",
        "                 (\"checkpoint: CheckpointConfig = CheckpointConfig()\", \"checkpoint: CheckpointConfig = field(default_factory=CheckpointConfig)\"),\n",
        "                 (\"common_eval: CommonEvalConfig = CommonEvalConfig()\", \"common_eval: CommonEvalConfig = field(default_factory=CommonEvalConfig)\"),\n",
        "                 (\"generation: GenerationConfig = GenerationConfig()\", \"generation: GenerationConfig = field(default_factory=GenerationConfig)\"),\n",
        "                 (\"optimization: OptimizationConfig = OptimizationConfig()\", \"optimization: OptimizationConfig = field(default_factory=OptimizationConfig)\"),\n",
        "                 (\"ema: EMAConfig = EMAConfig()\", \"ema: EMAConfig = field(default_factory=EMAConfig)\"), \n",
        "                 (\"bmuf: FairseqBMUFConfig = FairseqBMUFConfig()\", \"bmuf: FairseqBMUFConfig = field(default_factory=FairseqBMUFConfig)\"),\n",
        "                 (\"eval_lm: EvalLMConfig = EvalLMConfig()\", \"eval_lm: EvalLMConfig = field(default_factory=EvalLMConfig)\"),\n",
        "                 (\"interactive: InteractiveConfig = InteractiveConfig()\", \"interactive: InteractiveConfig = field(default_factory=InteractiveConfig)\"),\n",
        "            ]\n",
        "            for old, new in replacements:\n",
        "                configs_content = configs_content.replace(old, new)\n",
        "            \n",
        "            os.makedirs(os.path.dirname(configs_path), exist_ok=True)\n",
        "            with open(configs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(configs_content)\n",
        "            print(\"   âœ… configs.py patched and written.\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed to patch configs.py: {e}\")\n",
        "\n",
        "        # --- PART B: Recursive Patch for ALL other files ---\n",
        "        print(\"   ðŸ” Starting global recursive patch for other files...\")\n",
        "        \n",
        "        def apply_safe_patch(file_path):\n",
        "            try:\n",
        "                if os.path.basename(file_path) == \"configs.py\": return False # Skip handled file\n",
        "                \n",
        "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                original_content = content\n",
        "                modified = False\n",
        "                \n",
        "                # 0. ALWAYS DISABLE HYDRA INIT (Standard Check)\n",
        "                if \"hydra_init()\" in content and \"# hydra_init()\" not in content:\n",
        "                     content = content.replace(\"hydra_init()\", \"# hydra_init() # Disabled by Patcher\")\n",
        "                     modified = True\n",
        "                \n",
        "                # DATACLASS GUARD: Only apply regex if file uses dataclasses\n",
        "                is_dataclass = \"@dataclass\" in content or \"from dataclasses\" in content\n",
        "                \n",
        "                if is_dataclass:\n",
        "                    # 1. Regex for:  var: Type = Type()\n",
        "                    # STRICT NO-NEWLINE version to avoid matching if/while statements\n",
        "                    try:\n",
        "                        # Replaced \\s with [ \\t] to match only horizontal whitespace\n",
        "                        pattern1 = r'([ \\t]+\\w+)[ \\t]*:[ \\t]*([\\w\\.]+)[ \\t]*=[ \\t]*([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches1 = re.findall(pattern1, content)\n",
        "                        if matches1:\n",
        "                            def repl1(m):\n",
        "                                return f\"{m.group(1)}: {m.group(2)} = field(default_factory={m.group(3)})\"\n",
        "                            content = re.sub(pattern1, repl1, content)\n",
        "                            modified = True\n",
        "                    except Exception as re_e:\n",
        "                         print(f\"   âš ï¸ Regex 1 failed on {os.path.basename(file_path)}: {re_e}\")\n",
        "\n",
        "                    # 2. Regex for:  field(default=Type())\n",
        "                    try:\n",
        "                        pattern2 = r'field\\(default=([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches2 = re.findall(pattern2, content)\n",
        "                        if matches2:\n",
        "                            def repl2(m):\n",
        "                                return f\"field(default_factory={m.group(1)}\"\n",
        "                            content = re.sub(pattern2, repl2, content)\n",
        "                            modified = True\n",
        "                    except Exception as re_e:\n",
        "                         print(f\"   âš ï¸ Regex 2 failed on {os.path.basename(file_path)}: {re_e}\")\n",
        "\n",
        "                    # 3. Import Injection (SAFE MODE - String Replace)\n",
        "                    if modified and \"field(\" in content and \"from dataclasses import field\" not in content:\n",
        "                        if \"from dataclasses import dataclass\" in content:\n",
        "                             content = content.replace(\"from dataclasses import dataclass\", \"from dataclasses import dataclass, field\")\n",
        "                        elif \"import dataclasses\" in content:\n",
        "                             content = content.replace(\"import dataclasses\", \"import dataclasses\\nfrom dataclasses import field\")\n",
        "                        else:\n",
        "                             content = \"from dataclasses import field\\n\" + content\n",
        "                \n",
        "                if content != original_content:\n",
        "                    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(content)\n",
        "                    return True\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Error scanning {file_path}: {e}\")\n",
        "            return False\n",
        "\n",
        "        patch_count = 0\n",
        "        for root, dirs, files in os.walk(fairseq_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".py\"):\n",
        "                     if apply_safe_patch(os.path.join(root, file)):\n",
        "                         patch_count += 1\n",
        "        \n",
        "        print(f\"   âœ… Recursive patch applied to {patch_count} files.\")\n",
        "\n",
        "    # ==========================================================================\n",
        "\n",
        "    # 3. Trigger Training\n",
        "    print(\"ðŸ§  Starting Feature Extraction and Training...\")\n",
        "    \n",
        "    cwd_backup = os.getcwd()\n",
        "    \n",
        "    # Define Absolute paths\n",
        "    rvc_internal_dataset_dir = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"dataset\")\n",
        "    dataset_abs_path = os.path.join(rvc_internal_dataset_dir, PERSON_NAME)\n",
        "    logs_abs_path = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"logs\", PERSON_NAME)\n",
        "    \n",
        "    os.makedirs(dataset_abs_path, exist_ok=True)\n",
        "    os.makedirs(logs_abs_path, exist_ok=True)\n",
        "    \n",
        "    print(f\"... Moving audio files to {dataset_abs_path}\")\n",
        "    for audio_file in AUDIO_FILES:\n",
        "        if os.path.exists(audio_file):\n",
        "            shutil.copy(audio_file, os.path.join(dataset_abs_path, audio_file))\n",
        "\n",
        "    os.chdir(RVC_BACKEND_DIR)\n",
        "    \n",
        "    # DEBUG: Check file existence\n",
        "    print(\"ðŸ” Validating backend files...\")\n",
        "    target_script = \"infer/modules/train/extract/extract_f0_print.py\"\n",
        "    if not os.path.exists(target_script):\n",
        "        print(f\"âŒ CRITICAL: Script not found: {target_script}\")\n",
        "    \n",
        "    try:\n",
        "        def run_cmd(cmd, hide_output=False):\n",
        "            print(f\"Running: {cmd.split()[0]} ... (args hidden)\")\n",
        "            if hide_output:\n",
        "                result = subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, text=True)\n",
        "            else:\n",
        "                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "                \n",
        "            if result.returncode != 0:\n",
        "                print(f\"âŒ Command Failed!\\nSTDERR: {result.stderr}\")\n",
        "                raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            print(\"âœ… Done.\")\n",
        "            return result\n",
        "        \n",
        "        print(\"--- 1. Preprocessing Dataset ---\")\n",
        "        cmd_preprocess = f\"python infer/modules/train/preprocess.py '{dataset_abs_path}' 40000 2 '{logs_abs_path}' False 3.0\"\n",
        "        run_cmd(cmd_preprocess, hide_output=True)\n",
        "\n",
        "        print(\"--- 2. Extracting Pitch (F0) ---\")\n",
        "        run_cmd(f\"python infer/modules/train/extract/extract_f0_print.py '{logs_abs_path}' 2 rmvpe\", hide_output=True)\n",
        "        \n",
        "        print(\"--- 3. Extracting Features ---\")\n",
        "        run_cmd(f\"python infer/modules/train/extract_feature_print.py cuda 1 0 0 '{logs_abs_path}' v2\", hide_output=True)\n",
        "        \n",
        "        print(\"--- 4. Training Model ---\")\n",
        "        # Reduced batch size to 1 just in case, but 4 is usually fine on T4\n",
        "        cmd_train = f\"python infer/modules/train/train.py -e {PERSON_NAME} -sr 40k -ov 0 -bs 4 -te {EPOCHS} -pg 0 -if 0 -l 0 -c 0 -sw 0 -v v2\"\n",
        "        run_cmd(cmd_train, hide_output=False)\n",
        "        \n",
        "        # 4. Export Model\n",
        "        print(\"âœ… Training finished. Exporting model...\")\n",
        "        weights_dir = \"weights\"\n",
        "        pth_files = [f for f in os.listdir(weights_dir) if PERSON_NAME in f and \".pth\" in f]\n",
        "        if pth_files:\n",
        "             latest_model = sorted(pth_files)[-1]\n",
        "             target_model_path = os.path.join(cwd_backup, \"models\", f\"{PERSON_NAME}.pth\")\n",
        "             shutil.copy(os.path.join(weights_dir, latest_model), target_model_path)\n",
        "             print(f\"ðŸ† Model saved locally to: {target_model_path}\")\n",
        "             \n",
        "             drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "             if not os.path.exists(drive_voice_dir):\n",
        "                 os.makedirs(drive_voice_dir)\n",
        "             shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "             print(f\"â˜ï¸ Model backed up to Google Drive: {drive_voice_dir}\")\n",
        "        else:\n",
        "             print(\"âŒ No model file generated.\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training failed with error: {e}\")\n",
        "    finally:\n",
        "        os.chdir(cwd_backup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ­ Step 5: Voice Conversion\n",
        "\n",
        "Convert audio using any trained (or loaded) voice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from core.inference import VoiceConverter\n",
        "from utils.registry import discover_voices\n",
        "\n",
        "# List available voices (including those synced from Drive)\n",
        "available_voices = discover_voices(models_dir=\"models\")\n",
        "print(f\"Available voices: {available_voices}\")\n",
        "\n",
        "# Conversion parameters\n",
        "SOURCE_AUDIO = \"/content/source_audio.wav\"  # Path to source audio\n",
        "TARGET_VOICE = available_voices[0] if available_voices else None\n",
        "OUTPUT_PATH = \"/content/output_converted.wav\"\n",
        "\n",
        "if TARGET_VOICE:\n",
        "    print(f\"Converting audio to voice: {TARGET_VOICE}\")\n",
        "    registry = VoiceRegistry(models_dir=\"models\")\n",
        "    model_path = registry.get_model_path(TARGET_VOICE)\n",
        "    \n",
        "    if not model_path:\n",
        "         # Fallback check if registry needs refresh\n",
        "         registry.refresh()\n",
        "         model_path = registry.get_model_path(TARGET_VOICE)\n",
        "\n",
        "    if model_path:\n",
        "        converter = VoiceConverter(model_path, device=device)\n",
        "        try:\n",
        "            converter.convert(SOURCE_AUDIO, OUTPUT_PATH, pitch_shift=0.0)\n",
        "            print(f\"âœ… Conversion completed! Output saved to: {OUTPUT_PATH}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Conversion failed: {e}\")\n",
        "    else:\n",
        "        print(f\"âŒ Could not find model for {TARGET_VOICE}\")\n",
        "else:\n",
        "    print(\"âŒ No trained voices available.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}