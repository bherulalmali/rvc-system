{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfa4 RVC Voice Cloning System - Google Colab\n",
        "\n",
        "This notebook provides GPU access for users without local GPUs.\n",
        "\n",
        "**Features**:\n",
        "- \ud83d\udcbe **Google Drive Integration**: Automatically save and load trained models\n",
        "- \ud83d\ude80 **GPU Acceleration**: Uses Tesla T4/P100\n",
        "- \ud83e\udde0 **Real Training**: Uses official RVC backend for high-quality results\n",
        "- \ud83d\udd04 **RVC-Python**: Robust inference engine\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1.  Run all cells in order\n",
        "2.  Mount Google Drive when prompted\n",
        "3.  Use the training and inference cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd0c Step 1: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title \ud83d\udd0c Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create serialization directory on Drive\n",
        "DRIVE_RVC_DIR = \"/content/drive/MyDrive/RVC_Models\"\n",
        "os.makedirs(DRIVE_RVC_DIR, exist_ok=True)\n",
        "print(f\"\u2705 Google Drive mounted. Models will be saved to: {DRIVE_RVC_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Step 2: Clone Repository and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title \ud83d\udce6 Step 2: Clone Repository and Install Dependencies\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# \u26a0\ufe0f REPLACE WITH YOUR GITHUB REPO URL \u26a0\ufe0f\n",
        "REPO_URL = \"https://github.com/alakhsharmaa/RVCVoiceCloning.git\"\n",
        "REPO_DIR = \"RVCVoiceCloning\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
        "        print(\"\u2705 Repository cloned successfully\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"\u274c Failed to clone. Please check the REPO_URL above.\")\n",
        "else:\n",
        "    print(f\"Repository already exists at {REPO_DIR}\")\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    os.chdir(REPO_DIR)\n",
        "    print(f\"Working directory: {os.getcwd()}\")\n",
        "    # Removed requirements.txt install to prevent crashes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Step 3: Load Saved Models from Drive\n",
        "\n",
        "Syncs models from your Google Drive `RVC_Models` folder to the local workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title \ud83d\udd04 Step 3: Load Saved Models from Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "local_models_dir = \"models/finetuned_models\"\n",
        "os.makedirs(local_models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Syncing models from Drive...\")\n",
        "if os.path.exists(DRIVE_RVC_DIR):\n",
        "    synced_count = 0\n",
        "    for item in os.listdir(DRIVE_RVC_DIR):\n",
        "        drive_path = os.path.join(DRIVE_RVC_DIR, item)\n",
        "        if os.path.isdir(drive_path):\n",
        "            local_path = os.path.join(local_models_dir, item)\n",
        "            if not os.path.exists(local_path):\n",
        "                shutil.copytree(drive_path, local_path)\n",
        "                synced_count += 1\n",
        "                print(f\"Synced voice: {item}\")\n",
        "    \n",
        "    if synced_count == 0:\n",
        "        print(\"No new models found on Drive to sync.\")\n",
        "    else:\n",
        "        print(f\"\u2705 Synced {synced_count} models from Google Drive\")\n",
        "else:\n",
        "    print(\"Drive directory not found (should be empty if first run)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf93 Step 4: Train a New Voice (Real RVC Backend)\n",
        "\n",
        "1. Enter the name of the person/character.\n",
        "2. Click the upload button to select your `.wav` files.\n",
        "3. The system will process, train (50 epochs by default), and save the model to your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title \ud83c\udf93 Step 4: Train a New Voice (Real RVC Backend)\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import re\n",
        "import glob\n",
        "import sys\n",
        "import requests\n",
        "import json\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Inputs\n",
        "PERSON_NAME = \"my_voice\" # @param {type:\"string\"}\n",
        "EPOCHS = 50 # @param {type:\"integer\"}\n",
        "SAVE_FREQUENCY = 10 # @param {type:\"integer\"}\n",
        "\n",
        "print(f\"\ud83c\udfa4 Voice Name: {PERSON_NAME}\")\n",
        "print(f\"\ud83d\udd04 Epochs: {EPOCHS}\")\n",
        "\n",
        "# 2. Upload Audio\n",
        "print(\"\\n\ud83d\udcc2 Please upload your audio files (.wav)...\")\n",
        "uploaded = files.upload()\n",
        "AUDIO_FILES = list(uploaded.keys())\n",
        "\n",
        "if not AUDIO_FILES:\n",
        "    print(\"\u26a0\ufe0f No files uploaded. Please rerun this cell and upload audio.\")\n",
        "else:\n",
        "    print(f\"\ud83d\ude80 Initializing Real RVC Training for: {PERSON_NAME}\")\n",
        "    \n",
        "    # 1. Setup Official RVC Backend (STEALTH MODE - No Clone)\n",
        "    RVC_BACKEND_DIR = \"training_core\"\n",
        "    \n",
        "    # FORCE CLEANUP\n",
        "    if os.path.exists(RVC_BACKEND_DIR):\n",
        "        if not os.path.exists(os.path.join(RVC_BACKEND_DIR, \"infer\")):\n",
        "             print(\"\u26a0\ufe0f Detected broken backend from previous run. Deleting...\")\n",
        "             shutil.rmtree(RVC_BACKEND_DIR)\n",
        "             \n",
        "    if not os.path.exists(RVC_BACKEND_DIR):\n",
        "        print(\"\ud83d\udce5 Downloading core assets (Safe Mode)...\")\n",
        "        subprocess.run(\"wget https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/archive/refs/heads/main.zip -O rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(\"unzip -q rvc_core.zip\", shell=True, check=True)\n",
        "        subprocess.run(f\"mv Retrieval-based-Voice-Conversion-WebUI-main {RVC_BACKEND_DIR}\", shell=True, check=True)\n",
        "        subprocess.run(\"rm rvc_core.zip\", shell=True, check=True)\n",
        "        \n",
        "        for f in [\"README.md\", \"README.en.md\", \"docs\"]:\n",
        "            path = os.path.join(RVC_BACKEND_DIR, f)\n",
        "            if os.path.exists(path):\n",
        "                if os.path.isdir(path):\n",
        "                    shutil.rmtree(path)\n",
        "                else:\n",
        "                    os.remove(path)\n",
        "    else:\n",
        "        print(\"\u2705 Backend directory exists\")\n",
        "    \n",
        "    print(\"\ud83d\udce6 Installing Verified RVC Dependencies (SEQUENTIAL MODE)...\")\n",
        "    \n",
        "    def run_pip(pkg_name, cmd_override=None):\n",
        "        print(f\"... Installing {pkg_name}\")\n",
        "        cmd = cmd_override if cmd_override else f\"pip install --no-cache-dir {pkg_name}\"\n",
        "        res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0:\n",
        "            print(f\"\u274c FAILED {pkg_name} install! Output:\\n{res.stdout}\\n{res.stderr}\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    subprocess.run(\"sudo apt-get install -y libsndfile1-dev swig > /dev/null 2>&1\", shell=True, check=True)\n",
        "\n",
        "    run_pip(\"ninja\")\n",
        "    run_pip('\"numpy<2.0\"')\n",
        "    \n",
        "    # Use modern Hydra/Omegaconf for Python 3.12 support\n",
        "    print(\"... Installing modern omegaconf/hydra (wheels)\")\n",
        "    run_pip(\"omegaconf==2.3.0\")\n",
        "    run_pip(\"hydra-core==1.3.2\")\n",
        "    run_pip(\"antlr4-python3-runtime==4.9.3\") \n",
        "    run_pip(\"bitarray\") \n",
        "    run_pip(\"sacrebleu\")\n",
        "\n",
        "    deps = [\n",
        "        \"librosa==0.9.1\", \n",
        "        \"faiss-cpu\",\n",
        "        \"praat-parselmouth==0.4.3\",\n",
        "        \"pyworld==0.3.4\",\n",
        "        \"tensorboardX\",\n",
        "        \"torchcrepe\",\n",
        "        \"ffmpeg-python\",\n",
        "        \"av\",\n",
        "        \"scipy\",\n",
        "        \"protobuf==3.20.0\"\n",
        "    ]\n",
        "\n",
        "    for dep in deps:\n",
        "        run_pip(dep)\n",
        "\n",
        "    print(\"... Installing fairseq (wheel info override)\")\n",
        "    if not run_pip(\"fairseq==0.12.2\", \"pip install --no-cache-dir --no-deps fairseq==0.12.2\"):\n",
        "         print(\"\u26a0\ufe0f Wheel failed. Trying source...\")\n",
        "         run_pip(\"fairseq\", \"pip install --no-cache-dir git+https://github.com/facebookresearch/fairseq.git\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # \ud83d\udc0d PYTHON 3.12 COMPATIBILITY PATCHER (SAFE REGEX + MANUAL OVERRIDE)\n",
        "    # ==========================================================================\n",
        "    print(\"\ud83d\udee0\ufe0f Running Python 3.12 Compatibility Patcher (Clean-Slate Mode)...\")\n",
        "    \n",
        "    site_dirs = [p for p in sys.path if (\"site-packages\" in p or \"dist-packages\" in p) and os.path.isdir(p)]\n",
        "    if not site_dirs:\n",
        "        print(\"\u274c Could not locate package directory!\")\n",
        "    else:\n",
        "        base_dir = site_dirs[0]\n",
        "        fairseq_dir = os.path.join(base_dir, \"fairseq\")\n",
        "        \n",
        "        # --- PART A: Manual Fix for configs.py (CRITICAL) ---\n",
        "        configs_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/dataclass/configs.py\"\n",
        "        configs_path = os.path.join(fairseq_dir, \"dataclass\", \"configs.py\")\n",
        "        try:\n",
        "            print(\"   \u2b07\ufe0f Downloading pristine configs.py...\")\n",
        "            configs_content = requests.get(configs_url).text\n",
        "            print(\"   \ud83d\udd27 Patching configs.py...\")\n",
        "            replacements = [\n",
        "                 (\"common: CommonConfig = CommonConfig()\", \"common: CommonConfig = field(default_factory=CommonConfig)\"),\n",
        "                 (\"dataset: DatasetConfig = DatasetConfig()\", \"dataset: DatasetConfig = field(default_factory=DatasetConfig)\"),\n",
        "                 (\"distributed_training: DistributedTrainingConfig = DistributedTrainingConfig()\", \"distributed_training: DistributedTrainingConfig = field(default_factory=DistributedTrainingConfig)\"),\n",
        "                 (\"checkpoint: CheckpointConfig = CheckpointConfig()\", \"checkpoint: CheckpointConfig = field(default_factory=CheckpointConfig)\"),\n",
        "                 (\"common_eval: CommonEvalConfig = CommonEvalConfig()\", \"common_eval: CommonEvalConfig = field(default_factory=CommonEvalConfig)\"),\n",
        "                 (\"generation: GenerationConfig = GenerationConfig()\", \"generation: GenerationConfig = field(default_factory=GenerationConfig)\"),\n",
        "                 (\"optimization: OptimizationConfig = OptimizationConfig()\", \"optimization: OptimizationConfig = field(default_factory=OptimizationConfig)\"),\n",
        "                 (\"ema: EMAConfig = EMAConfig()\", \"ema: EMAConfig = field(default_factory=EMAConfig)\"), \n",
        "                 (\"bmuf: FairseqBMUFConfig = FairseqBMUFConfig()\", \"bmuf: FairseqBMUFConfig = field(default_factory=FairseqBMUFConfig)\"),\n",
        "                 (\"eval_lm: EvalLMConfig = EvalLMConfig()\", \"eval_lm: EvalLMConfig = field(default_factory=EvalLMConfig)\"),\n",
        "                 (\"interactive: InteractiveConfig = InteractiveConfig()\", \"interactive: InteractiveConfig = field(default_factory=InteractiveConfig)\"),\n",
        "            ]\n",
        "            for old, new in replacements:\n",
        "                configs_content = configs_content.replace(old, new)\n",
        "            with open(configs_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(configs_content)\n",
        "            print(\"   \u2705 configs.py patched.\")\n",
        "        except Exception as e:\n",
        "            print(f\"   \u274c Failed to patch configs.py: {e}\")\n",
        "\n",
        "        # --- PART A.2: Manual Fix for transformer_config.py (CRITICAL) ---\n",
        "        trans_url = \"https://raw.githubusercontent.com/facebookresearch/fairseq/v0.12.2/fairseq/models/transformer/transformer_config.py\"\n",
        "        trans_path = os.path.join(fairseq_dir, \"models\", \"transformer\", \"transformer_config.py\")\n",
        "        try:\n",
        "            print(\"   \u2b07\ufe0f Downloading pristine transformer_config.py...\")\n",
        "            trans_content = requests.get(trans_url).text\n",
        "            print(\"   \ud83d\udd27 Patching transformer_config.py...\")\n",
        "            replacements_t = [\n",
        "                (\"quant_noise: QuantNoiseConfig = field(default=QuantNoiseConfig())\", \"quant_noise: QuantNoiseConfig = field(default_factory=QuantNoiseConfig)\"),\n",
        "                 # Generic match using safe replacement for one-liners\n",
        "                (\"encoder: EncDecBaseConfig = EncDecBaseConfig()\", \"encoder: EncDecBaseConfig = field(default_factory=EncDecBaseConfig)\"),\n",
        "                (\"decoder: DecoderConfig = DecoderConfig()\", \"decoder: DecoderConfig = field(default_factory=DecoderConfig)\"),\n",
        "                 # Add explicit import for field if missing (it usually is)\n",
        "                (\"import re\", \"import re\\nfrom dataclasses import field\"),\n",
        "            ]\n",
        "            for old, new in replacements_t:\n",
        "                trans_content = trans_content.replace(old, new)\n",
        "            \n",
        "            # Fallback if EncDecBaseConfig format is slightly different (e.g. spaces)\n",
        "            # Using strict check to avoid overwriting twice\n",
        "            \n",
        "            with open(trans_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(trans_content)\n",
        "            print(\"   \u2705 transformer_config.py patched.\")\n",
        "        except Exception as e:\n",
        "             print(f\"   \u274c Failed to patch transformer_config.py: {e}\")\n",
        "\n",
        "        # --- PART A.3: Manual Fix for checkpoint_utils.py (PyTorch 2.6+) ---\n",
        "        ckpt_utils_path = os.path.join(fairseq_dir, \"checkpoint_utils.py\")\n",
        "        try:\n",
        "            print(\"   \ud83d\udd27 Patching checkpoint_utils.py for PyTorch 2.6+...\")\n",
        "            with open(ckpt_utils_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                ckpt_content = f.read()\n",
        "            \n",
        "            # Fix torch.load defaults\n",
        "            ckpt_content = ckpt_content.replace(\n",
        "                'state = torch.load(f, map_location=torch.device(\"cpu\"))', \n",
        "                'state = torch.load(f, map_location=torch.device(\"cpu\"), weights_only=False)'\n",
        "            )\n",
        "            \n",
        "            with open(ckpt_utils_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(ckpt_content)\n",
        "            print(\"   \u2705 checkpoint_utils.py patched.\")\n",
        "        except Exception as e:\n",
        "             print(f\"   \u274c Failed to patch checkpoint_utils.py: {e}\")\n",
        "\n",
        "        # --- PART A.4: Manual Fix for utils.py (Matplotlib 3.8+ tostring_rgb fix) ---\n",
        "        cwd_backup = os.getcwd()\n",
        "        utils_py_path = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"infer/lib/train/utils.py\")\n",
        "        try:\n",
        "            print(\"   \ud83d\udd27 Patching utils.py for Matplotlib 3.8+ (tostring_rgb removal)...\")\n",
        "            if os.path.exists(utils_py_path):\n",
        "                with open(utils_py_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    utils_content = f.read()\n",
        "                \n",
        "                # Simple direct replacement of the deprecated line\n",
        "                # Old: data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=\"\")\n",
        "                # New: RGBA -> RGB -> Flatten to match old expected format\n",
        "                if \"tostring_rgb\" in utils_content:\n",
        "                    utils_content = utils_content.replace(\n",
        "                        'data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep=\"\")',\n",
        "                        'fig.canvas.draw(); data = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (4,))[:, :, :3].flatten()'\n",
        "                    )\n",
        "                    with open(utils_py_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(utils_content)\n",
        "                    print(\"   \u2705 utils.py patched for Matplotlib 3.8+.\")\n",
        "                else:\n",
        "                    print(\"   \u2139\ufe0f utils.py already patched or tostring_rgb not found.\")\n",
        "            else:\n",
        "                print(f\"   \u26a0\ufe0f Could not find utils.py at {utils_py_path}\")\n",
        "        except Exception as e:\n",
        "             print(f\"   \u274c Failed to patch utils.py: {e}\")\n",
        "\n",
        "        # --- PART B: Recursive Patch for ALL other files ---\n",
        "        print(\"   \ud83d\udd0d Starting global recursive patch for other files...\")\n",
        "        \n",
        "        def apply_safe_patch(file_path):\n",
        "            try:\n",
        "                fname = os.path.basename(file_path)\n",
        "                if fname in [\"configs.py\", \"transformer_config.py\"]: return False # Skip handled files\n",
        "                \n",
        "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    content = f.read()\n",
        "                \n",
        "                original_content = content\n",
        "                modified = False\n",
        "                \n",
        "                # 0. DISABLE HYDRA INIT\n",
        "                if \"hydra_init()\" in content and \"# hydra_init()\" not in content:\n",
        "                     content = content.replace(\"hydra_init()\", \"# hydra_init() # Disabled by Patcher\")\n",
        "                     modified = True\n",
        "                \n",
        "                is_dataclass = \"@dataclass\" in content or \"from dataclasses\" in content\n",
        "                \n",
        "                if is_dataclass:\n",
        "                    # 0. SELF-HEALING (Use lambda to avoid group ref errors)\n",
        "                    heal_pattern = r'field\\(default_factory=([\\w\\.]+)\\)\\(\\)'\n",
        "                    if re.search(heal_pattern, content):\n",
        "                        content = re.sub(heal_pattern, lambda m: f\"field(default_factory={m.group(1)})\", content)\n",
        "                        modified = True\n",
        "\n",
        "                    # 1. Regex for:  var: Type = Type()\n",
        "                    try:\n",
        "                        pattern1 = r'([ \\t]+\\w+)[ \\t]*:[ \\t]*([\\w\\.]+)[ \\t]*=[ \\t]*([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches1 = re.findall(pattern1, content)\n",
        "                        if matches1:\n",
        "                            def repl1(m):\n",
        "                                type_name = m.group(3)\n",
        "                                if type_name in [\"II\", \"Optional\", \"List\", \"Dict\", \"Union\", \"Any\", \"field\"]:\n",
        "                                    return m.group(0) \n",
        "                                return f\"{m.group(1)}: {m.group(2)} = field(default_factory={type_name})\"\n",
        "                            content = re.sub(pattern1, repl1, content)\n",
        "                            modified = True\n",
        "                    except Exception:\n",
        "                         pass\n",
        "\n",
        "                    # 2. Regex for:  field(default=Type())\n",
        "                    try:\n",
        "                        pattern2 = r'field\\(default=([\\w\\.]+)\\([ \\t]*\\)'\n",
        "                        matches2 = re.findall(pattern2, content)\n",
        "                        if matches2:\n",
        "                            def repl2(m):\n",
        "                                return f\"field(default_factory={m.group(1)}\"\n",
        "                            content = re.sub(pattern2, repl2, content)\n",
        "                            modified = True\n",
        "                    except Exception:\n",
        "                         pass\n",
        "\n",
        "                    # 3. Import Injection\n",
        "                    if modified and \"field(\" in content and \"from dataclasses import field\" not in content:\n",
        "                        if \"from dataclasses import dataclass\" in content:\n",
        "                             content = content.replace(\"from dataclasses import dataclass\", \"from dataclasses import dataclass, field\")\n",
        "                        elif \"import dataclasses\" in content:\n",
        "                             content = content.replace(\"import dataclasses\", \"import dataclasses\\nfrom dataclasses import field\")\n",
        "                        else:\n",
        "                             content = \"from dataclasses import field\\n\" + content\n",
        "                \n",
        "                if content != original_content:\n",
        "                    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(content)\n",
        "                    return True\n",
        "            except Exception as e:\n",
        "                # Silent fail for other files to avoid clogging logs, key files checks above.\n",
        "                pass\n",
        "            return False\n",
        "\n",
        "        patch_count = 0\n",
        "        for root, dirs, files in os.walk(fairseq_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".py\"):\n",
        "                     if apply_safe_patch(os.path.join(root, file)):\n",
        "                         patch_count += 1\n",
        "        \n",
        "        print(f\"   \u2705 Recursive patch applied to {patch_count} files.\")\n",
        "\n",
        "    # ==========================================================================\n",
        "\n",
        "    # 3. Trigger Training\n",
        "    print(\"\ud83e\udde0 Starting Feature Extraction and Training...\")\n",
        "    \n",
        "    cwd_backup = os.getcwd()\n",
        "    \n",
        "    # Define Absolute paths\n",
        "    rvc_internal_dataset_dir = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"dataset\")\n",
        "    dataset_abs_path = os.path.join(rvc_internal_dataset_dir, PERSON_NAME)\n",
        "    logs_abs_path = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"logs\", PERSON_NAME)\n",
        "    \n",
        "    # --- DEBUGGING / CLEAN START ---\n",
        "    if os.path.exists(logs_abs_path):\n",
        "        print(f\"\u26a0\ufe0f Clearning logs directory for fresh start: {logs_abs_path}\")\n",
        "        shutil.rmtree(logs_abs_path)\n",
        "    \n",
        "    os.makedirs(dataset_abs_path, exist_ok=True)\n",
        "    os.makedirs(logs_abs_path, exist_ok=True)\n",
        "    # CRITICAL: Create weights directory so savee() doesn't fail\n",
        "    os.makedirs(\"weights\", exist_ok=True)\n",
        "    os.makedirs(\"assets/weights\", exist_ok=True) # RVC often saves here\n",
        "    \n",
        "    print(f\"... Moving audio files to {dataset_abs_path}\")\n",
        "    for audio_file in AUDIO_FILES:\n",
        "        if os.path.exists(audio_file):\n",
        "            shutil.copy(audio_file, os.path.join(dataset_abs_path, audio_file))\n",
        "            \n",
        "    # --- NEW: VERIFY/DOWNLOAD PRETRAINED MODELS ---\n",
        "    print(\"\u2b07\ufe0f Verifying/Downloading Pretrained Models...\")\n",
        "    rvc_assets_dir = os.path.join(cwd_backup, RVC_BACKEND_DIR, \"assets\")\n",
        "    hubert_dir = os.path.join(rvc_assets_dir, \"hubert\")\n",
        "    rmvpe_dir = os.path.join(rvc_assets_dir, \"rmvpe\")\n",
        "    pretrained_dir = os.path.join(rvc_assets_dir, \"pretrained_v2\")\n",
        "    os.makedirs(hubert_dir, exist_ok=True)\n",
        "    os.makedirs(rmvpe_dir, exist_ok=True)\n",
        "    os.makedirs(pretrained_dir, exist_ok=True)\n",
        "\n",
        "    # 1. Hubert\n",
        "    hubert_path = os.path.join(hubert_dir, \"hubert_base.pt\")\n",
        "    if not os.path.exists(hubert_path):\n",
        "        # Check if user uploaded it to root /content/\n",
        "        # cwd_backup is usually /content/rvc-system, so typical root is ../\n",
        "        possible_locs = [\n",
        "            os.path.join(cwd_backup, \"hubert_base.pt\"), \n",
        "            \"/content/hubert_base.pt\"\n",
        "        ]\n",
        "        found = False\n",
        "        for loc in possible_locs:\n",
        "            if os.path.exists(loc):\n",
        "                print(f\"   Found hubert_base.pt at {loc}, moving to {hubert_path}...\")\n",
        "                shutil.move(loc, hubert_path)\n",
        "                found = True\n",
        "                break\n",
        "        \n",
        "        if not found:\n",
        "             print(\"   Downloading hubert_base.pt from HuggingFace...\")\n",
        "             subprocess.run(f\"wget -q https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -O {hubert_path}\", shell=True)\n",
        "\n",
        "    # 2. RMVPE\n",
        "    rmvpe_path = os.path.join(rmvpe_dir, \"rmvpe.pt\")\n",
        "    if not os.path.exists(rmvpe_path):\n",
        "         possible_locs = [\n",
        "            os.path.join(cwd_backup, \"rmvpe.pt\"), \n",
        "            \"/content/rmvpe.pt\"\n",
        "        ]\n",
        "         found = False\n",
        "         for loc in possible_locs:\n",
        "            if os.path.exists(loc):\n",
        "                print(f\"   Found rmvpe.pt at {loc}, moving to {rmvpe_path}...\")\n",
        "                shutil.move(loc, rmvpe_path)\n",
        "                found = True\n",
        "                break\n",
        "         if not found:\n",
        "             print(\"   Downloading rmvpe.pt from HuggingFace...\")\n",
        "             subprocess.run(f\"wget -q https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -O {rmvpe_path}\", shell=True)\n",
        "             \n",
        "    # 3. Base Models (G and D)\n",
        "    f0G_path = os.path.join(pretrained_dir, \"f0G40k.pth\")\n",
        "    f0D_path = os.path.join(pretrained_dir, \"f0D40k.pth\")\n",
        "    if not os.path.exists(f0G_path):\n",
        "         print(\"   Downloading f0G40k.pth from HuggingFace...\")\n",
        "         subprocess.run(f\"wget -q https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G40k.pth -O {f0G_path}\", shell=True)\n",
        "    if not os.path.exists(f0D_path):\n",
        "         print(\"   Downloading f0D40k.pth from HuggingFace...\")\n",
        "         subprocess.run(f\"wget -q https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D40k.pth -O {f0D_path}\", shell=True)\n",
        "\n",
        "    # ----------------------------------------------\n",
        "\n",
        "    os.chdir(RVC_BACKEND_DIR)\n",
        "    \n",
        "    # DEBUG: Check file existence\n",
        "    print(\"\ud83d\udd0d Validating backend files...\")\n",
        "    target_script = \"infer/modules/train/extract/extract_f0_print.py\"\n",
        "    if not os.path.exists(target_script):\n",
        "        print(f\"\u274c CRITICAL: Script not found: {target_script}\")\n",
        "    \n",
        "    try:\n",
        "        def run_cmd(cmd, hide_output=False):\n",
        "            print(f\"Running: {cmd}\") # FULL COMMAND\n",
        "            if hide_output:\n",
        "                result = subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, text=True)\n",
        "                if result.returncode != 0:\n",
        "                    raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            else:\n",
        "                # USE RUN WITH CAPTURE BUT PRINT ON FAILURE (Safe for syntax errors)\n",
        "                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "                # Print the output anyway for debug\n",
        "                if \"train.py\" in cmd: # Always print for train.py\n",
        "                     print(result.stdout)\n",
        "                     if result.stderr:\n",
        "                         # Filter out common TF warning spam from detailed log\n",
        "                         filtered_err = \"\\n\".join([l for l in result.stderr.split(\"\\n\") if \"TensorFlow\" not in l])\n",
        "                         print(\"\u26a0\ufe0f STDERR: \" + filtered_err)\n",
        "                \n",
        "                if result.returncode != 0:\n",
        "                    print(f\"\u274c Command Failed with exit code {result.returncode}\")\n",
        "                    print(f\"   STDOUT: {result.stdout}\")\n",
        "                    print(f\"   STDERR: {result.stderr}\")\n",
        "                    raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "            print(\"\u2705 Done.\")\n",
        "        \n",
        "        print(\"--- 1. Preprocessing Dataset ---\")\n",
        "        cmd_preprocess = f\"python infer/modules/train/preprocess.py '{dataset_abs_path}' 40000 2 '{logs_abs_path}' False 3.0\"\n",
        "        run_cmd(cmd_preprocess, hide_output=False) # Enable log\n",
        "        \n",
        "        # DEBUG: Check 1_16k_wavs (Simple confirmation)\n",
        "        wavs_16k = os.path.join(logs_abs_path, \"1_16k_wavs\")\n",
        "        if os.path.exists(wavs_16k):\n",
        "             files_16k = os.listdir(wavs_16k)\n",
        "             print(f\"   \u2139\ufe0f 1_16k_wavs content ({len(files_16k)} files): {files_16k[:5]}...\")\n",
        "        else:\n",
        "             print(\"   \u274c 1_16k_wavs not created! Preprocess failed.\")\n",
        "\n",
        "        print(\"--- 2. Extracting Pitch (F0) ---\")\n",
        "        run_cmd(f\"python infer/modules/train/extract/extract_f0_print.py '{logs_abs_path}' 2 rmvpe\", hide_output=False) # Enable log\n",
        "        \n",
        "        print(\"--- 3. Extracting Features ---\")\n",
        "        # Added 'False' (is_half) to fix argument parsing mismatch\n",
        "        # ENABLE OUTPUT TO DEBUG MISSING DIR\n",
        "        run_cmd(f\"python infer/modules/train/extract_feature_print.py cuda 1 0 0 '{logs_abs_path}' v2 False\", hide_output=False)\n",
        "        \n",
        "        print(\"--- 4. Training Model ---\")\n",
        "        \n",
        "        # --- CONFIG FIX: GENERATE 40k.json DYNAMICALLY ---\n",
        "        target_config = os.path.join(logs_abs_path, \"config.json\")\n",
        "\n",
        "        # --- CRITICAL FIX: GENERATE filelist.txt ---\n",
        "        print(\"... Generating filelist.txt (Mandatory for train.py)\")\n",
        "        gt_wavs_dir = os.path.join(logs_abs_path, \"0_gt_wavs\")\n",
        "        \n",
        "        # DYNAMICALY FIND FEATURE DIR\n",
        "        # RVC V2 often uses 3_feature768 or 3_feature256 depending on version/embedder\n",
        "        import glob\n",
        "        feature_dirs = glob.glob(os.path.join(logs_abs_path, \"3_feature*\"))\n",
        "        if feature_dirs:\n",
        "             feature_dir = feature_dirs[0]\n",
        "             print(f\"   Found feature dir: {feature_dir}\")\n",
        "        else:\n",
        "             # Fallback to default expected\n",
        "             feature_dir = os.path.join(logs_abs_path, \"3_feature256\") \n",
        "             print(f\"   \u26a0\ufe0f Feature dir not found by glob. Defaulting to: {feature_dir}\")\n",
        "\n",
        "        f0_dir = os.path.join(logs_abs_path, \"2a_f0\")\n",
        "        f0nsf_dir = os.path.join(logs_abs_path, \"2b-f0nsf\")\n",
        "        \n",
        "        filelist_path = os.path.join(logs_abs_path, \"filelist.txt\")\n",
        "        \n",
        "        valid_entries = 0\n",
        "        with open(filelist_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            if os.path.exists(gt_wavs_dir):\n",
        "                for wav_file in os.listdir(gt_wavs_dir):\n",
        "                    if wav_file.endswith(\".wav\"):\n",
        "                        # Format: GT_WAV | FEATURE | PITCH | PITCHF | SID\n",
        "                        # Filenames are usually {idx0}_{idx1}.wav\n",
        "                        base_name = wav_file.replace(\".wav\", \"\")\n",
        "                        \n",
        "                        gt_path = os.path.join(gt_wavs_dir, wav_file)\n",
        "                        # Feature is .npy\n",
        "                        feat_path = os.path.join(feature_dir, f\"{base_name}.npy\")\n",
        "                        # Pitch is .wav.npy\n",
        "                        pitch_path = os.path.join(f0_dir, f\"{wav_file}.npy\")\n",
        "                        pitchf_path = os.path.join(f0nsf_dir, f\"{wav_file}.npy\")\n",
        "                        \n",
        "                        # Verify existence (optional, but good for debug)\n",
        "                        if os.path.exists(feat_path) and os.path.exists(pitch_path):\n",
        "                            line = f\"{gt_path}|{feat_path}|{pitch_path}|{pitchf_path}|0\"\n",
        "                            f.write(line + \"\\n\")\n",
        "                            valid_entries += 1\n",
        "        \n",
        "        if valid_entries == 0:\n",
        "            print(\"\u274c SYSTEM ERROR: No valid training data found! Check if extract_feature ran correctly.\")\n",
        "            # Just listing dirs to see what happened\n",
        "            print(f\"   GT Dir exists: {os.path.exists(gt_wavs_dir)}\")\n",
        "            print(f\"   Feat Dir exists: {os.path.exists(feature_dir)} ({feature_dir})\")\n",
        "            print(f\"   Pitch Dir exists: {os.path.exists(f0_dir)}\")\n",
        "        else:\n",
        "            print(f\"\u2705 Generated filelist.txt with {valid_entries} samples.\")\n",
        "\n",
        "        # --- DYNAMIC BATCH SIZE ---\n",
        "        # If we have fewer samples than batch_size, the epoch might be skipped or fail to save\n",
        "        optimal_batch_size = min(4, valid_entries)\n",
        "        if optimal_batch_size < 1: optimal_batch_size = 1\n",
        "        print(f\"   \u2696\ufe0f  Auto-Adjusted Batch Size: {optimal_batch_size} (samples: {valid_entries})\")\n",
        "\n",
        "        print(\"... Generating config.json for 40k sample rate\")\n",
        "        # Synthesized from 48k.json structure but adapted for 40k\n",
        "        config_content = {\n",
        "            \"train\": {\n",
        "                \"log_interval\": 10,  # Lower log interval to see progress on small data\n",
        "                \"seed\": 1234,\n",
        "                \"epochs\": 20000,\n",
        "                \"learning_rate\": 1e-4,\n",
        "                \"betas\": [0.8, 0.99],\n",
        "                \"eps\": 1e-9,\n",
        "                \"batch_size\": optimal_batch_size,\n",
        "                \"fp16_run\": True,\n",
        "                \"lr_decay\": 0.999875,\n",
        "                \"segment_size\": 12800,\n",
        "                \"init_lr_ratio\": 1,\n",
        "                \"warmup_epochs\": 0,\n",
        "                \"c_mel\": 45,\n",
        "                \"c_kl\": 1.0\n",
        "            },\n",
        "            \"data\": {\n",
        "                \"max_wav_value\": 32768.0,\n",
        "                \"sampling_rate\": 40000,\n",
        "                \"filter_length\": 2048,\n",
        "                \"hop_length\": 400,\n",
        "                \"win_length\": 2048,\n",
        "                \"n_mel_channels\": 128,\n",
        "                \"mel_fmin\": 0.0,\n",
        "                \"mel_fmax\": None,\n",
        "                \"training_files\": f\"{logs_abs_path}/filelist.txt\"\n",
        "            },\n",
        "            \"model\": {\n",
        "                \"inter_channels\": 192,\n",
        "                \"hidden_channels\": 192,\n",
        "                \"filter_channels\": 768,\n",
        "                \"n_heads\": 2,\n",
        "                \"n_layers\": 6,\n",
        "                \"kernel_size\": 3,\n",
        "                \"p_dropout\": 0,\n",
        "                \"resblock\": \"1\",\n",
        "                \"resblock_kernel_sizes\": [3, 7, 11],\n",
        "                \"resblock_dilation_sizes\": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "                \"upsample_rates\": [10, 10, 2, 2],\n",
        "                \"upsample_initial_channel\": 512,\n",
        "                # FIXED: KERNE SIZE 16 to match f0G40k.pth pretrained model\n",
        "                \"upsample_kernel_sizes\": [16, 16, 4, 4], # Was [20, 20, 4, 4]\n",
        "                \"use_spectral_norm\": False,\n",
        "                \"gin_channels\": 256,\n",
        "                \"spk_embed_dim\": 109\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        with open(target_config, \"w\") as f:\n",
        "            json.dump(config_content, f, indent=2)\n",
        "        print(f\"\u2705 Generated config.json at {target_config}\")\n",
        "\n",
        "        # --- DEBUG: AGGRESSIVE INJECT TRACING INTO TRAIN.PY ---\n",
        "        # (REMOVED: The issue was arguments/logic, we don't need to break syntax anymore)\n",
        "        \n",
        "        # --- DYNAMIC SAFE INTERVAL CALCULATION ---\n",
        "        # Ensure we always save at least once, even for short runs\n",
        "        real_epoch = int(EPOCHS)\n",
        "        real_freq = int(SAVE_FREQUENCY)\n",
        "        \n",
        "        # AGGRESSIVE SAVE STRATEGY for short runs\n",
        "        if real_epoch < 50:\n",
        "             print(\"   \u26a0\ufe0f Short run detected! Forcing save_every_epoch = 1\")\n",
        "             real_freq = 1\n",
        "        elif real_epoch < real_freq:\n",
        "            print(f\"   \u26a0\ufe0f Total epochs ({real_epoch}) < Save Frequency ({real_freq}). Force setting save frequency to {real_epoch}.\")\n",
        "            real_freq = real_epoch\n",
        "        elif real_freq <= 0:\n",
        "            real_freq = 1\n",
        "\n",
        "        # UPDATED FLAGS: \n",
        "        # -se (save_every_epoch)\n",
        "        # -bs (batch_size) -> overridden by config logic usually, but passing for argument correctness\n",
        "        # -te (total_epoch)\n",
        "        # -l 1 (if_latest) -> FORCE SAVE LATEST to ensure we get a G_latest.pth if all else fails\n",
        "        # -pg assets/pretrained_v2/f0G40k.pth\n",
        "        # -pd assets/pretrained_v2/f0D40k.pth\n",
        "        # -f0 1 (ENABLE F0: Critical for proper dataloader usage!)\n",
        "        \n",
        "        # ENVIRONMENT VARS FOR STABLE DDP\n",
        "        os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "        os.environ[\"MASTER_PORT\"] = \"12355\"\n",
        "        \n",
        "        cmd_train = f\"python infer/modules/train/train.py -e {PERSON_NAME} -sr 40k -se {real_freq} -bs {optimal_batch_size} -te {real_epoch} -pg assets/pretrained_v2/f0G40k.pth -pd assets/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v v2\"\n",
        "        run_cmd(cmd_train, hide_output=False)\n",
        "        \n",
        "        # --- 5. Train Index (Faiss) ---\n",
        "        print(\"--- 5. Training Index (Faiss) ---\")\n",
        "        cmd_index = f\"python infer/modules/train/train_index.py {PERSON_NAME} v2 {EPOCHS} {feature_dir}\"\n",
        "        run_cmd(cmd_index, hide_output=False)\n",
        "\n",
        "        # 4. Export Model\n",
        "        print(\"\u2705 Training finished. Exporting model...\")\n",
        "        \n",
        "        # Fallback check for weights in both possible locations\n",
        "        possible_dirs = [\"assets/weights\", \"weights\"]\n",
        "        pth_files = []\n",
        "        used_dir = \"\"\n",
        "        \n",
        "        for w_dir in possible_dirs:\n",
        "             if os.path.exists(w_dir):\n",
        "                 found = [f for f in os.listdir(w_dir) if PERSON_NAME in f and \".pth\" in f]\n",
        "                 if found:\n",
        "                     pth_files = found\n",
        "                     used_dir = w_dir\n",
        "                     break\n",
        "        \n",
        "        if pth_files:\n",
        "             latest_model = sorted(pth_files)[-1]\n",
        "             source_path = os.path.join(used_dir, latest_model)\n",
        "             target_model_path = os.path.join(cwd_backup, \"models\", \"finetuned_models\", f\"{PERSON_NAME}.pth\")\n",
        "             \n",
        "             # Ensure local models dir exists\n",
        "             os.makedirs(os.path.join(cwd_backup, \"models\", \"finetuned_models\"), exist_ok=True)\n",
        "             \n",
        "             shutil.copy(source_path, target_model_path)\n",
        "             print(f\"\ud83c\udfc6 Model saved locally to: {target_model_path}\")\n",
        "             \n",
        "             drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "             if not os.path.exists(drive_voice_dir):\n",
        "                 os.makedirs(drive_voice_dir)\n",
        "             shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "             print(f\"\u2601\ufe0f Model backed up to Google Drive: {drive_voice_dir}\")\n",
        "             \n",
        "             # Export Index\n",
        "             index_files = [f for f in os.listdir(logs_abs_path) if f.endswith('.index') and \"added\" in f]\n",
        "             if index_files:\n",
        "                 latest_index = sorted(index_files)[-1]\n",
        "                 source_index = os.path.join(logs_abs_path, latest_index)\n",
        "                 target_index_path = os.path.join(cwd_backup, \"models\", \"finetuned_models\", f\"{PERSON_NAME}.index\")\n",
        "                 shutil.copy(source_index, target_index_path)\n",
        "                 shutil.copy(target_index_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.index\"))\n",
        "                 print(f\"\u2601\ufe0f Index backed up to Google Drive: {os.path.join(drive_voice_dir, f'{PERSON_NAME}.index')}\")\n",
        "             else:\n",
        "                 print(\"\u26a0\ufe0f No .index file found in logs.\")\n",
        "        else:\n",
        "             print(\"\u274c No model file generated in weights/. Using MANUAL FALLBACK...\")\n",
        "             \n",
        "             # --- MANUAL CHECKPOINT CONVERSION FALLBACK ---\n",
        "             if os.path.exists(logs_abs_path):\n",
        "                  checkpoints = [f for f in os.listdir(logs_abs_path) if \"G_\" in f and \".pth\" in f]\n",
        "                  if checkpoints:\n",
        "                       # Find latest checkpoint by number\n",
        "                       # G_0.pth, G_100.pth, etc.\n",
        "                       def get_step(name):\n",
        "                           try:\n",
        "                               return int(re.search(r\"G_(\\d+)\", name).group(1))\n",
        "                           except:\n",
        "                               return 0\n",
        "                       latest_ckpt = sorted(checkpoints, key=get_step)[-1]\n",
        "                       latest_ckpt_path = os.path.join(logs_abs_path, latest_ckpt)\n",
        "                       print(f\"\u26a0\ufe0f Found raw checkpoint: {latest_ckpt_path}. Converting manually...\")\n",
        "                       \n",
        "                       try:\n",
        "                           # Load checkpoint\n",
        "                           print(\"... Loading checkpoint (CPU)\")\n",
        "                           ckpt = torch.load(latest_ckpt_path, map_location=\"cpu\")\n",
        "                           opt = OrderedDict()\n",
        "                           opt[\"weight\"] = {}\n",
        "                           if \"model\" in ckpt:\n",
        "                               ckpt_model = ckpt[\"model\"]\n",
        "                           else:\n",
        "                               ckpt_model = ckpt\n",
        "                           \n",
        "                           # Extract weights\n",
        "                           for key in ckpt_model.keys():\n",
        "                               if \"enc_q\" in key:\n",
        "                                   continue\n",
        "                               opt[\"weight\"][key] = ckpt_model[key].half()\n",
        "                           \n",
        "                           # Add Config (Synthesized 40k)\n",
        "                           opt[\"config\"] = [\n",
        "                                1025, 32, 192, 192, 768, 2, 6, 3, 0, \"1\",\n",
        "                                [3, 7, 11], [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "                                [10, 10, 2, 2], 512, [20, 20, 4, 4], 109, 256, 40000\n",
        "                           ]\n",
        "                           opt[\"info\"] = \"ManualConversion_Epoch50\"\n",
        "                           opt[\"sr\"] = \"40k\"\n",
        "                           opt[\"f0\"] = 1 # rmvpe used\n",
        "                           opt[\"version\"] = \"v2\"\n",
        "                           \n",
        "                           # Save\n",
        "                           target_model_path = os.path.join(cwd_backup, \"models\", \"finetuned_models\", f\"{PERSON_NAME}.pth\")\n",
        "                           os.makedirs(os.path.join(cwd_backup, \"models\", \"finetuned_models\"), exist_ok=True)\n",
        "                           torch.save(opt, target_model_path)\n",
        "                           print(f\"\ud83c\udfc6 Saved manually converted model to: {target_model_path}\")\n",
        "                           \n",
        "                           # Backup\n",
        "                           drive_voice_dir = os.path.join(DRIVE_RVC_DIR, PERSON_NAME)\n",
        "                           if not os.path.exists(drive_voice_dir):\n",
        "                               os.makedirs(drive_voice_dir)\n",
        "                           shutil.copy(target_model_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.pth\"))\n",
        "                           print(f\"\u2601\ufe0f Model backed up to Google Drive: {drive_voice_dir}\")\n",
        "                           \n",
        "                           # Export Index\n",
        "                           index_files = [f for f in os.listdir(logs_abs_path) if f.endswith('.index') and \"added\" in f]\n",
        "                           if index_files:\n",
        "                               latest_index = sorted(index_files)[-1]\n",
        "                               source_index = os.path.join(logs_abs_path, latest_index)\n",
        "                               target_index_path = os.path.join(cwd_backup, \"models\", \"finetuned_models\", f\"{PERSON_NAME}.index\")\n",
        "                               shutil.copy(source_index, target_index_path)\n",
        "                               shutil.copy(target_index_path, os.path.join(drive_voice_dir, f\"{PERSON_NAME}.index\"))\n",
        "                               print(f\"\u2601\ufe0f Index backed up to Google Drive: {os.path.join(drive_voice_dir, f'{PERSON_NAME}.index')}\")\n",
        "                           else:\n",
        "                               print(\"\u26a0\ufe0f No .index file found in logs.\")\n",
        "                           \n",
        "                       except Exception as e:\n",
        "                           print(f\"\u274c Manual conversion failed: {e}\")\n",
        "                           import traceback\n",
        "                           traceback.print_exc()\n",
        "                  else:\n",
        "                       print(f\"\u274c CRITICAL: No G_*.pth checkpoints found in {logs_abs_path}!\")\n",
        "                       print(\"This implies the training loop did not save ANY checkpoints. Check epoch count vs save_interval.\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Training failed with error: {e}\")\n",
        "    finally:\n",
        "        os.chdir(cwd_backup)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfad Step 5: Voice Conversion\n",
        "\n",
        "Convert audio using any trained (or loaded) voice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title \ud83c\udfad Step 5: Voice Conversion\n",
        "import sys\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
        "\n",
        "from core.inference.converter import VoiceConverter\n",
        "from utils.registry import VoiceRegistry, discover_voices\n",
        "from utils.device import get_device\n",
        "\n",
        "MODELS_DIR = \"models/finetuned_models\"\n",
        "device = get_device()\n",
        "\n",
        "# List available voices \n",
        "available_voices = discover_voices(models_dir=MODELS_DIR)\n",
        "print(f\"Available voices: {available_voices}\")\n",
        "\n",
        "if not available_voices:\n",
        "    print(\"\u274c No trained voices found. Please train a voice first.\")\n",
        "else:\n",
        "    print(\"\\n\ud83d\udcc2 Please upload your Source Audio file (wav/mp3)...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        SOURCE_AUDIO = list(uploaded.keys())[0]\n",
        "        print(f\"   \u2705 Source Audio: {SOURCE_AUDIO}\")\n",
        "        \n",
        "        # Interactive Model Selection\n",
        "        print(\"\\nSelect a voice model:\")\n",
        "        for idx, v in enumerate(available_voices):\n",
        "            print(f\"{idx}: {v}\")\n",
        "        \n",
        "        try:\n",
        "            selection = int(input(\"Enter the number of the voice model: \"))\n",
        "            TARGET_VOICE = available_voices[selection]\n",
        "        except (ValueError, IndexError):\n",
        "            print(\"\u26a0\ufe0f Invalid input, defaulting to first model.\")\n",
        "            TARGET_VOICE = available_voices[0]\n",
        "\n",
        "        # Use person-specific output folder\n",
        "        OUTPUT_DIR = os.path.join(\"data/outputs\", TARGET_VOICE)\n",
        "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "        OUTPUT_PATH = os.path.join(OUTPUT_DIR, f\"converted_{TARGET_VOICE}.wav\")\n",
        "        \n",
        "        print(f\"\ud83d\ude80 Converting '{SOURCE_AUDIO}' using '{TARGET_VOICE}'...\")\n",
        "        registry = VoiceRegistry(models_dir=MODELS_DIR)\n",
        "        model_path = registry.get_model_path(TARGET_VOICE)\n",
        "        \n",
        "        if model_path:\n",
        "            converter = VoiceConverter(model_path, device=device)\n",
        "            try:\n",
        "                # Auto-detect index\n",
        "                index_path = None\n",
        "                model_folder = os.path.dirname(model_path)\n",
        "                import glob\n",
        "                idx_files = glob.glob(os.path.join(model_folder, \"*.index\"))\n",
        "                if idx_files:\n",
        "                    index_path = idx_files[0]\n",
        "                    print(f\"   \u2139\ufe0f Using index file: {os.path.basename(index_path)}\")\n",
        "                \n",
        "                converter.convert(\n",
        "                    source_audio_path=SOURCE_AUDIO, \n",
        "                    output_path=OUTPUT_PATH, \n",
        "                    pitch_shift=0.0,\n",
        "                    index_path=index_path\n",
        "                )\n",
        "                print(f\"\u2705 Conversion completed! Output saved to: {OUTPUT_PATH}\")\n",
        "                \n",
        "                # Auto-download\n",
        "                files.download(OUTPUT_PATH)\n",
        "            except Exception as e:\n",
        "                print(f\"\u274c Conversion failed: {e}\")\n",
        "        else:\n",
        "            print(f\"\u274c Could not find model path for {TARGET_VOICE}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}