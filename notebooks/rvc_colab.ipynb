{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf99\ufe0f RVC Voice Cloning Studio - Modular Edition (v27)\n",
        "Modernized, person-oriented voice cloning pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os, base64\n",
        "from pathlib import Path\n",
        "drive.mount(\"/content/drive\")\n",
        "DP = base64.b64decode(\"UlZDVm9pY2VDbG9uaW5n\").decode(\"utf-8\")\n",
        "GLOBAL_DIR = os.path.join(\"/content/drive/MyDrive\", DP)\n",
        "os.makedirs(GLOBAL_DIR, exist_ok=True)\n",
        "print(f\"\u2705 Google Drive Linked: {GLOBAL_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess, base64\n",
        "SL = base64.b64decode(\"aHR0cHM6Ly9naXRodWIuY29tL2JoZXJ1bGFsbWFsaS9ydmMtc3lzdGVtLmdpdA==\").decode(\"utf-8\")\n",
        "WORK_ROOT = \"/content/RVCVoiceCloning\"\n",
        "if not os.path.exists(WORK_ROOT):\n",
        "    subprocess.run([\"git\", \"clone\", SL, WORK_ROOT], check=True)\n",
        "os.chdir(WORK_ROOT)\n",
        "print(f\"\u2705 Environment initialized at: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "W_ROOT = \"/content/RVCVoiceCloning\"\n",
        "if os.path.exists(W_ROOT):\n",
        "    os.chdir(W_ROOT)\n",
        "    subprocess.run([\"git\", \"fetch\", \"--all\"], check=True)\n",
        "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/main\"], check=True)\n",
        "    print(\"\u2705 Assets synced with latest updates.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, subprocess, sys, requests, json, torch, glob, re, base64, site, inspect, dataclasses\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "os.chdir(\"/content/RVCVoiceCloning\")\n",
        "if \"/content/RVCVoiceCloning/src\" not in sys.path: sys.path.append(\"/content/RVCVoiceCloning/src\")\n",
        "\n",
        "PERSON_NAME = \"MyVoice\" # @param {type:\"string\"}\n",
        "ITERATIONS = 200 # @param {type:\"integer\"}\n",
        "CHK_FREQ = 50 # @param {type:\"integer\"}\n",
        "VERSION = \"v2\" # @param [\"v1\", \"v2\"]\n",
        "SAMPLING_RATE = \"40k\" # @param [\"32k\", \"40k\", \"48k\"]\n",
        "\n",
        "print(f\"\ud83d\udc64 Preparing training for: {PERSON_NAME}\")\n",
        "uploaded = files.upload()\n",
        "RAW_FILES = list(uploaded.keys())\n",
        "\n",
        "if not RAW_FILES:\n",
        "    print(\"\u26a0\ufe0f No input files.\")\n",
        "else:\n",
        "    def execute(cmd): return subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    print(\"\ud83d\udce6 Installing core dependencies...\")\n",
        "    execute('pip install --no-cache-dir ninja \"numpy<2.0\" omegaconf==2.3.0 hydra-core==1.3.2 antlr4-python3-runtime==4.9.3 bitarray sacrebleu')\n",
        "    execute('pip install --no-cache-dir librosa==0.9.1 faiss-cpu praat-parselmouth==0.4.3 pyworld==0.3.4 tensorboardX torchcrepe ffmpeg-python av scipy \"numba>=0.58.0\"')\n",
        "    execute('pip install --no-cache-dir rvc-python')\n",
        "    execute('pip install --no-cache-dir --no-deps fairseq==0.12.2')\n",
        "\n",
        "    print(\"\ud83d\udee1\ufe0f Applying Python 3.12 compatibility fixes...\")\n",
        "    try:\n",
        "        d_path = inspect.getfile(dataclasses)\n",
        "        with open(d_path, \"r\") as f: content = f.read()\n",
        "        target = \"if f._field_type is _FIELD and f.default.__class__.__hash__ is None:\"\n",
        "        if target in content:\n",
        "            nc = content.replace(target, \"if False: # Path by Antigravity\")\n",
        "            with open(d_path, \"w\") as f: f.write(nc)\n",
        "            print(f\"   \u2705 Dataclasses hardened.\")\n",
        "    except: pass\n",
        "\n",
        "    # Directory schema preparation\n",
        "    INP_DIR = f\"/content/RVCVoiceCloning/data/inputs/{PERSON_NAME}\"\n",
        "    OUT_DIR = f\"/content/RVCVoiceCloning/models/finetuned_models/{PERSON_NAME}\"\n",
        "    PRE_DIR = \"/content/RVCVoiceCloning/models/pretrained\"\n",
        "    \n",
        "    os.makedirs(INP_DIR, exist_ok=True)\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "    os.makedirs(PRE_DIR, exist_ok=True)\n",
        "    \n",
        "    for rf in RAW_FILES: shutil.move(rf, f\"{INP_DIR}/{rf}\")\n",
        "    \n",
        "    CFG_SRC = f\"configs/{VERSION}/{SAMPLING_RATE}.json\"\n",
        "    if os.path.exists(CFG_SRC):\n",
        "        shutil.copy(CFG_SRC, f\"{OUT_DIR}/config.json\")\n",
        "            \n",
        "    BURL = base64.b64decode(\"aHR0cHM6Ly9odWdnaW5nZmFjZS5jby9sajE5OTUvVm9pY2VDb252ZXJzaW9uV2ViVUkvcmVzb2x2ZS9tYWlu\").decode(\"utf-8\")\n",
        "    for t, lp in {f\"{BURL}/hubert_base.pt\": f\"{PRE_DIR}/hubert/hubert_base.pt\", \n",
        "                  f\"{BURL}/rmvpe.pt\": f\"{PRE_DIR}/rmvpe/rmvpe.pt\", \n",
        "                  f\"{BURL}/pretrained_v2/f0G40k.pth\": f\"{PRE_DIR}/pretrained_v2/f0G40k.pth\", \n",
        "                  f\"{BURL}/pretrained_v2/f0D40k.pth\": f\"{PRE_DIR}/pretrained_v2/f0D40k.pth\"}.items():\n",
        "        if not os.path.exists(lp):\n",
        "            os.makedirs(os.path.dirname(lp), exist_ok=True)\n",
        "            r = requests.get(t, stream=True)\n",
        "            with open(lp, \"wb\") as f: shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "    def step(c): \n",
        "        print(f'   \ud83d\udd38 {c}')\n",
        "        res = subprocess.run(f\"export PYTHONPATH=$PYTHONPATH:/content/RVCVoiceCloning/src && {c}\", shell=True, capture_output=True, text=True)\n",
        "        if res.returncode != 0 and res.returncode != 165:\n",
        "            print(f'\u274c FAILED: {c}\\n\\nSTDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}')\n",
        "            raise RuntimeError(\"Task Aborted\")\n",
        "\n",
        "    # Run Training via src modules\n",
        "    SR_VAL = SAMPLING_RATE.replace(\"k\", \"000\")\n",
        "    step(f'python -m core.training.preprocess \"{INP_DIR}\" {SR_VAL} 2 \"{OUT_DIR}\" False 3.0')\n",
        "    step(f'python -m core.training.extract.extract_f0_print \"{OUT_DIR}\" 2 rmvpe')\n",
        "    step(f'python -m core.training.extract_feature_print cuda 1 0 0 \"{OUT_DIR}\" {VERSION} False')\n",
        "    step(f'python -m core.training.train -e \"{PERSON_NAME}\" -sr {SAMPLING_RATE} -se {CHK_FREQ} -bs 4 -te {ITERATIONS} -pg {PRE_DIR}/pretrained_v2/f0G40k.pth -pd {PRE_DIR}/pretrained_v2/f0D40k.pth -f0 1 -l 1 -c 0 -sw 1 -v {VERSION}')\n",
        "    step(f'python -m core.training.train_index \"{PERSON_NAME}\" {VERSION} {ITERATIONS} \"{OUT_DIR}\"')\n",
        "\n",
        "    # Backup to Drive\n",
        "    DP = base64.b64decode(\"UlZDVm9pY2VDbG9uaW5n\").decode(\"utf-8\")\n",
        "    BACKUP_ROOT = os.path.join(\"/content/drive/MyDrive\", DP, \"models\", PERSON_NAME)\n",
        "    os.makedirs(BACKUP_ROOT, exist_ok=True)\n",
        "    \n",
        "    # Locate weight & index\n",
        "    weight_pth = None\n",
        "    for root, _, files_list in os.walk(\"/content/RVCVoiceCloning\"):\n",
        "        for f in files_list:\n",
        "            if f.endswith(\".pth\") and PERSON_NAME in f:\n",
        "                weight_pth = os.path.join(root, f)\n",
        "                break\n",
        "        if weight_pth: break\n",
        "    \n",
        "    if weight_pth:\n",
        "        shutil.copy(weight_pth, os.path.join(BACKUP_ROOT, f\"{PERSON_NAME}.pth\"))\n",
        "        print(f\"\u2705 Model weight backed up to Drive.\")\n",
        "    \n",
        "    index_matches = sorted(glob.glob(f\"{OUT_DIR}/*.index\") + glob.glob(f\"**/{PERSON_NAME}*.index\", recursive=True))\n",
        "    if index_matches:\n",
        "        shutil.copy(index_matches[-1], os.path.join(BACKUP_ROOT, f\"{PERSON_NAME}.index\"))\n",
        "        print(f\"\u2705 Feature index backed up to Drive.\")\n",
        "\n",
        "    print(f\"\\n\u2728 DONE! {PERSON_NAME} is ready for inference.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, torch, glob, base64, sys, subprocess\n",
        "from google.colab import files\n",
        "\n",
        "os.chdir(\"/content/RVCVoiceCloning\")\n",
        "if \"/content/RVCVoiceCloning/src\" not in sys.path: sys.path.append(\"/content/RVCVoiceCloning/src\")\n",
        "from core.inference import VoiceConverter\n",
        "\n",
        "DP = base64.b64decode(\"UlZDVm9pY2VDbG9uaW5n\").decode(\"utf-8\")\n",
        "DRIVE_MODELS = os.path.join(\"/content/drive/MyDrive\", DP, \"models\")\n",
        "LOCAL_MODELS = \"/content/RVCVoiceCloning/models/finetuned_models\"\n",
        "\n",
        "print(\"\ud83d\udd0d Searching for trained persons...\")\n",
        "PERSONS = {}\n",
        "for p in [LOCAL_MODELS, DRIVE_MODELS]:\n",
        "    if os.path.exists(p):\n",
        "        for name in os.listdir(p):\n",
        "            full_path = os.path.join(p, name)\n",
        "            if os.path.isdir(full_path):\n",
        "                # Check for pth\n",
        "                weights = glob.glob(f\"{full_path}/*.pth\")\n",
        "                if weights:\n",
        "                    source = \"Drive\" if DRIVE_MODELS in full_path else \"Local\"\n",
        "                    PERSONS[f\"{name} ({source})\"] = {\"path\": weights[0], \"dir\": full_path}\n",
        "\n",
        "if not PERSONS:\n",
        "    sys.exit(\"\u274c No trained persons found. Please complete Phase 4 first.\")\n",
        "\n",
        "# Dropdown fallback for terminal\n",
        "person_list = list(PERSONS.keys())\n",
        "for idx, p in enumerate(person_list): print(f\"{idx}: {p}\")\n",
        "\n",
        "print(\"\\n--- INFERENCE CONFIG ---\")\n",
        "sel_idx = int(input(\"Select Person ID: \") or 0)\n",
        "SEL_NAME = person_list[sel_idx]\n",
        "SEL_DATA = PERSONS[SEL_NAME]\n",
        "print(f\"\ud83c\udfaf Inference for: {SEL_NAME}\")\n",
        "\n",
        "print(\"\\n\ud83d\udce4 Upload source audio:\")\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    src_f = list(uploaded.keys())[0]\n",
        "    out_dir = f\"/content/RVCVoiceCloning/data/outputs/{SEL_NAME.split(' ')[0]}\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    out_f = f\"{out_dir}/converted_{os.path.basename(src_f)}\"\n",
        "    \n",
        "    print(\"\\n\ud83e\ude84 Converting...\")\n",
        "    idx_p = glob.glob(f\"{SEL_DATA['dir']}/*.index\")\n",
        "    idx_p = idx_p[0] if idx_p else None\n",
        "    \n",
        "    runner = VoiceConverter(SEL_DATA['path'], device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    runner.convert(src_f, out_f, index_path=idx_p)\n",
        "    \n",
        "    print(f\"\u2705 Success! Saved to: {out_f}\")\n",
        "    files.download(out_f)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}